{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import required packages\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "JZvOBNymUu_r"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JrAldZprTDH",
        "outputId": "5ab3392f-b736-4c2a-e1ac-184f4b5e5c50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Step 1: Read the CSV file\n",
        "csv_file_path = 'BBBP.csv'  # Replace with the actual path to your CSV file\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Step 2: Extract SMILES strings from the fourth column\n",
        "smiles_column = df.iloc[:, 3]\n",
        "\n",
        "# Identify all unique molecules in the dataset\n",
        "all_molecules = set(\"\".join(smiles_column))\n",
        "\n",
        "# Step 3: Create a one-hot encoder\n",
        "one_hot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
        "\n",
        "# Fit the encoder on the unique molecules\n",
        "one_hot_encoder.fit([[mol] for mol in all_molecules])\n",
        "\n",
        "# Step 4: Encode each structure into a vector\n",
        "encoded_structures = []\n",
        "\n",
        "for smiles in smiles_column:\n",
        "    # Transform the SMILES string into a list of characters\n",
        "    mol_chars = list(smiles)\n",
        "\n",
        "    # Transform each character into its one-hot vector\n",
        "    mol_one_hot = one_hot_encoder.transform([[char] for char in mol_chars])\n",
        "\n",
        "    # Sum the one-hot vectors to obtain the structure vector\n",
        "    structure_vector = mol_one_hot.sum(axis=0)\n",
        "\n",
        "    # Append the structure vector to the list\n",
        "    encoded_structures.append(structure_vector)\n",
        "\n",
        "# Convert the list of structure vectors to a DataFrame\n",
        "encoded_df = pd.DataFrame(encoded_structures)\n",
        "\n",
        "# Add labels and other columns from the original DataFrame\n",
        "encoded_df['Label'] = df['p_np']  # Assuming 'Label' is the column with labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the length of each SMILES\n",
        "df['smiles_length'] = df['smiles'].apply(len)\n",
        "\n",
        "# Display a histogram of the distribution of string lengths\n",
        "plt.hist(df['smiles_length'], bins=17, edgecolor='black')\n",
        "plt.title('Distribution of SMILES Lengths')\n",
        "plt.xlabel('SMILES Length')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "mHPhCf8RUptz",
        "outputId": "4f012dc3-250b-4b89-e58d-e70d68991408"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHHCAYAAABZbpmkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABCzUlEQVR4nO3de3zP9f//8ft757ETYweZWQgLyaG10MlqjlEqhOYQnzRF0adUIh1EyPFDnz41OqD0KfoIYU4phEhJTsmEbc4zh5nt+fvDd+9fb5vTvLf39nK7Xi6vy8X7+Xq+X8/Hc6+33Hu9nq/3bMYYIwAAAItyc3UBAAAARYmwAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wA1zCsGHDZLPZimWsu+++W3fffbf99fLly2Wz2fTFF18Uy/jdu3dX1apVi2WswsrMzNQTTzyhsLAw2Ww2DRgwwNUloQj8+eefstlsGj16tKtLgUUQdnDdmDZtmmw2m33z8fFRpUqVFB8frwkTJujEiRNOGWf//v0aNmyYNm3a5JTjOVNJru1KvPXWW5o2bZr69u2rjz/+WN26dbto37Nnz2r8+PG69dZbFRAQoKCgIN18883q06ePfv/9d3u/v38uVq1ale84xhhFRETIZrOpTZs2DvtsNpv69etnf32l/0hXrVrV4bP4961FixYOfVetWqWWLVvqhhtukI+Pj6pUqaK2bdtqxowZlxxDOh+g69Spc9l+rjJ//nwNGzbM1WXgOuDh6gKA4jZ8+HBFRUUpOztbqampWr58uQYMGKCxY8fq66+/Vr169ex9X3nlFb344otXdfz9+/frtddeU9WqVVW/fv0rft+iRYuuapzCuFRt77//vnJzc4u8hmuxdOlS3X777Ro6dOhl+3bo0EELFixQ586d1bt3b2VnZ+v333/XvHnzdMcdd6hWrVoO/X18fDRjxgw1bdrUoX3FihX666+/5O3t7dS51K9fXwMHDszXXqlSJfufZ8+erY4dO6p+/frq37+/ypUrp927d2vlypV6//339dhjjzm1puI2f/58TZ48mcCDIkfYwXWnZcuWatSokf314MGDtXTpUrVp00YPPPCAtm7dKl9fX0mSh4eHPDyK9q/JqVOnVKZMGXl5eRXpOJfj6enp0vGvRHp6uqKjoy/bb926dZo3b57efPNNvfTSSw77Jk2apGPHjuV7T6tWrTR79mxNmDDB4ZzPmDFDDRs21KFDh665/r+74YYb1LVr10v2GTZsmKKjo7VmzZp8n4/09HSn1gNYGbexAEn33nuvhgwZoj179uiTTz6xtxe0Zmfx4sVq2rSpgoKC5Ofnp5o1a9r/QV2+fLkaN24sSerRo4f91sS0adMk/f/bChs2bNCdd96pMmXK2N974ZqdPDk5OXrppZcUFhamsmXL6oEHHtDevXsd+lStWlXdu3fP996/H/NytRW0ZufkyZMaOHCgIiIi5O3trZo1a2r06NEyxjj0y7udM2fOHNWpU0fe3t66+eabtXDhwoJ/4BdIT09Xr169FBoaKh8fH91yyy2aPn26fX/e+qXdu3frm2++sdf+559/Fni8Xbt2SZKaNGmSb5+7u7uCg4PztXfu3FmHDx/W4sWL7W1nz57VF1984bIrKLt27VLjxo0LDMIhISFOG2fBggVq1qyZypYtK39/f7Vu3Vpbtmxx6NO9e3f5+flp3759at++vfz8/FSxYkUNGjRIOTk5Dn0PHz6sbt262W8fJiQk6Oeff873eZs8ebIkOdzGu9C///1vVatWTd7e3mrcuLHWrVvnsD81NVU9evRQ5cqV5e3trfDwcLVr1+6inw1cn7iyA/yfbt266aWXXtKiRYvUu3fvAvts2bJFbdq0Ub169TR8+HB5e3tr586d+v777yVJtWvX1vDhw/Xqq6+qT58+atasmSTpjjvusB/j8OHDatmypTp16qSuXbsqNDT0knW9+eabstlseuGFF5Senq5x48YpLi5OmzZtsl+BuhJXUtvfGWP0wAMPaNmyZerVq5fq16+vb7/9Vs8//7z27dund99916H/qlWr9OWXX+qpp56Sv7+/JkyYoA4dOiglJaXAcJHn9OnTuvvuu7Vz507169dPUVFRmj17trp3765jx46pf//+ql27tj7++GM9++yzqly5sv32T8WKFQs8ZmRkpCTp008/VZMmTa7o6lzVqlUVGxurmTNnqmXLlpLOh4Djx4+rU6dOmjBhwmWPcTWys7MLvFpUtmxZ+3mNjIxUcnKy/vrrL1WuXNmp4+f5+OOPlZCQoPj4eI0cOVKnTp3SlClT1LRpU23cuNEhAOfk5Cg+Pl4xMTEaPXq0lixZojFjxqhatWrq27evJCk3N1dt27bVjz/+qL59+6pWrVqaO3euEhISHMb9xz/+of3792vx4sX6+OOPC6xtxowZOnHihP7xj3/IZrNp1KhReuihh/THH3/Yr0R26NBBW7Zs0dNPP62qVasqPT1dixcvVkpKSolfcI9iZIDrRFJSkpFk1q1bd9E+gYGB5tZbb7W/Hjp0qPn7X5N3333XSDIHDx686DHWrVtnJJmkpKR8++666y4jyUydOrXAfXfddZf99bJly4wkc8MNN5iMjAx7++eff24kmfHjx9vbIiMjTUJCwmWPeanaEhISTGRkpP31nDlzjCTzxhtvOPR7+OGHjc1mMzt37rS3STJeXl4ObT///LORZCZOnJhvrL8bN26ckWQ++eQTe9vZs2dNbGys8fPzc5h7ZGSkad269SWPZ4wxubm59p91aGio6dy5s5k8ebLZs2dPvr5//1xMmjTJ+Pv7m1OnThljjHnkkUfMPffcc9GxJZnExET76927dxtJ5p133rlkfZGRkUZSgduIESPs/T744AP7z/aee+4xQ4YMMd99953Jycm57M/AmPPn/+abb77o/hMnTpigoCDTu3dvh/bU1FQTGBjo0J6QkGAkmeHDhzv0vfXWW03Dhg3tr//73/8aSWbcuHH2tpycHHPvvffm++wlJiaagv4Zyvs5BgcHmyNHjtjb586daySZ//3vf8YYY44ePXpFP2+A21jA3/j5+V3yqaygoCBJ0ty5cwu9mNfb21s9evS44v6PP/64/P397a8ffvhhhYeHa/78+YUa/0rNnz9f7u7ueuaZZxzaBw4cKGOMFixY4NAeFxenatWq2V/Xq1dPAQEB+uOPPy47TlhYmDp37mxv8/T01DPPPKPMzEytWLHiqmu32Wz69ttv9cYbb6hcuXKaOXOmEhMTFRkZqY4dOxa4ZkeSHn30UZ0+fVrz5s3TiRMnNG/evCK7hRUTE6PFixfn2/7+c+jZs6cWLlyou+++W6tWrdLrr7+uZs2aqUaNGvrhhx+uuYbFixfr2LFj6ty5sw4dOmTf3N3dFRMTo2XLluV7z5NPPunwulmzZg7neOHChfL09HS4Ourm5qbExMSrrq9jx44qV66cw1iS7OP5+vrKy8tLy5cv19GjR6/6+Lh+cBsL+JvMzMxLroXo2LGj/vOf/+iJJ57Qiy++qObNm+uhhx7Sww8/LDe3K/t/hxtuuOGqFiPXqFHD4bXNZlP16tWLfE3Cnj17VKlSJYegJZ2/HZa3/++qVKmS7xjlypW77D9Ce/bsUY0aNfL9/C42zpXy9vbWyy+/rJdfflkHDhzQihUrNH78eH3++efy9PR0WJuVp2LFioqLi9OMGTN06tQp5eTk6OGHHy7U+JdToUIFxcXFXbZffHy84uPjderUKW3YsEGfffaZpk6dqjZt2uj333+/prU7O3bskHR+zVpBAgICHF77+Pjku3V44Tnes2ePwsPDVaZMGYd+1atXv+r6LvxM5QWfvPG8vb01cuRIDRw4UKGhobr99tvVpk0bPf744woLC7vq8WBdXNkB/s9ff/2l48ePX/I/yr6+vlq5cqWWLFmibt26afPmzerYsaPuu+++fIs0L3UMZ7vYFx9eaU3O4O7uXmC7uWAxsyuEh4erU6dOWrlypWrUqKHPP/9c586dK7DvY489pgULFmjq1Klq2bKl/Wqeq5UpU0bNmjXTpEmT9Morr+jo0aP5rq5drbyrkx9//HGBV5nmzp3r0P9i57ioXMlnasCAAdq+fbtGjBghHx8fDRkyRLVr19bGjRuLq0yUAoQd4P/kLZKMj4+/ZD83Nzc1b95cY8eO1W+//aY333xTS5cutV/yd/Y3Luf933ceY4x27tzpsPiyXLlyBd6aufCqyNXUFhkZqf379+e7rZf3hXx5i4CvVWRkpHbs2JHvtqCzx5HO3x6rV6/eRRcHS9KDDz4oNzc3rVmzpsR+j03eVyccOHDgmo6Td9sxJCREcXFx+baCng68nMjISB04cECnTp1yaN+5c2e+vs76u1KtWjUNHDhQixYt0q+//qqzZ89qzJgxTjk2rIGwA+j8l9W9/vrrioqKUpcuXS7a78iRI/na8r6cLysrS9L5p2kkXXRdyNX66KOPHALHF198oQMHDtifGJLO/8d+zZo1Onv2rL1t3rx5+R5Rv5raWrVqpZycHE2aNMmh/d1335XNZnMY/1q0atVKqamp+uyzz+xt586d08SJE+Xn56e77rrrqo+5Y8cOpaSk5Gs/duyYVq9erXLlyl30SS4/Pz9NmTJFw4YNU9u2ba96bGdKTk4usD1vvVbNmjWv6fjx8fEKCAjQW2+9pezs7Hz7Dx48WKhjZmdn6/3337e35ebm2h8z/7tr/bty6tQpnTlzxqGtWrVq8vf3t/99BCTW7OA6tGDBAv3+++86d+6c0tLStHTpUi1evFiRkZH6+uuv5ePjc9H3Dh8+XCtXrlTr1q0VGRmp9PR0/etf/1LlypXt37xbrVo1BQUFaerUqfL391fZsmUVExOjqKioQtVbvnx5NW3aVD169FBaWprGjRun6tWrOywAfeKJJ/TFF1+oRYsWevTRR7Vr1y598sknDguGr7a2tm3b6p577tHLL7+sP//8U7fccosWLVqkuXPnasCAAfmOXVh9+vTRe++9p+7du2vDhg2qWrWqvvjiC33//fcaN25cvjVDV+Lnn3/WY489ppYtW6pZs2YqX7689u3bp+nTp2v//v0aN27cJW/JXPiY9NVKTk7O94+wJLVv397+6xv27dtX4LohPz8/tW/fXpLUrl07RUVFqW3btqpWrZpOnjypJUuW6H//+58aN258RWHs4MGDeuONN/K15wX7KVOmqFu3bmrQoIE6deqkihUrKiUlRd98842aNGmSL+xeTvv27XXbbbdp4MCB2rlzp2rVqqWvv/7a/j8Kf7+a07BhQ0nSM888o/j4eLm7u6tTp05XPNb27dvVvHlzPfroo4qOjpaHh4e++uorpaWlXdVxcB1w7cNgQPHJe8Q4b/Py8jJhYWHmvvvuM+PHj3d4xDnPhY+eJycnm3bt2plKlSoZLy8vU6lSJdO5c2ezfft2h/fNnTvXREdHGw8PD4fHbS/1KPDFHj2fOXOmGTx4sAkJCTG+vr6mdevWBT5CPWbMGHPDDTcYb29v06RJE7N+/fp8x7xUbRc+em7M+UeTn332WVOpUiXj6elpatSoYd555x2Tm5vr0E8XPIKd52KPxF8oLS3N9OjRw1SoUMF4eXmZunXrFvh4/JU+ep6Wlmbefvttc9ddd5nw8HDj4eFhypUrZ+69917zxRdfOPS9kq8kuNjYF84775Hpi20ff/yx/VgX6/P3czBz5kzTqVMnU61aNePr62t8fHxMdHS0efnllwv8vF4o7/H7grbmzZvb+y1btszEx8ebwMBA4+PjY6pVq2a6d+9u1q9fb++TkJBgypYtm2+MC/+OGGPMwYMHzWOPPWb8/f1NYGCg6d69u/n++++NJDNr1ix7v3Pnzpmnn37aVKxY0dhsNvtxLvUIvyQzdOhQY4wxhw4dMomJiaZWrVqmbNmyJjAw0MTExJjPP//8sj8bXF9sxpSA1YMAAEubM2eOHnzwQa1atarAb7YGihJhBwDgVKdPn3Z46jAnJ0f333+/1q9fr9TU1CJ5IhG4FNbsAACc6umnn9bp06cVGxurrKwsffnll/rhhx/01ltvEXTgElzZAQA41YwZMzRmzBjt3LlTZ86cUfXq1dW3b1/169fP1aXhOkXYAQAAlsb37AAAAEsj7AAAAEtjgbLOf7vn/v375e/v7/Sv+gcAAEXDGKMTJ06oUqVKl/xlzIQdSfv371dERISrywAAAIWwd+9eVa5c+aL7CTuS/evo9+7dq4CAABdXAwAArkRGRoYiIiIu+2tlCDv6/7+rJSAggLADAEApc7klKCxQBgAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlubh6gLgPCkpKTp06FCRj1OhQgVVqVKlyMcBAMAZCDsWkZKSopq1auvM6VNFPpaPbxlt+30rgQcAUCoQdizi0KFDOnP6lILbDJRncESRjZN9eK8OzxujQ4cOEXYAAKUCYcdiPIMj5B1W3dVlAABQYrBAGQAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWJpLw05OTo6GDBmiqKgo+fr6qlq1anr99ddljLH3Mcbo1VdfVXh4uHx9fRUXF6cdO3Y4HOfIkSPq0qWLAgICFBQUpF69eikzM7O4pwMAAEogl4adkSNHasqUKZo0aZK2bt2qkSNHatSoUZo4caK9z6hRozRhwgRNnTpVa9euVdmyZRUfH68zZ87Y+3Tp0kVbtmzR4sWLNW/ePK1cuVJ9+vRxxZQAAEAJ4+HKwX/44Qe1a9dOrVu3liRVrVpVM2fO1I8//ijp/FWdcePG6ZVXXlG7du0kSR999JFCQ0M1Z84cderUSVu3btXChQu1bt06NWrUSJI0ceJEtWrVSqNHj1alSpVcMzkAAFAiuPTKzh133KHk5GRt375dkvTzzz9r1apVatmypSRp9+7dSk1NVVxcnP09gYGBiomJ0erVqyVJq1evVlBQkD3oSFJcXJzc3Ny0du3aAsfNyspSRkaGwwYAAKzJpVd2XnzxRWVkZKhWrVpyd3dXTk6O3nzzTXXp0kWSlJqaKkkKDQ11eF9oaKh9X2pqqkJCQhz2e3h4qHz58vY+FxoxYoRee+01Z08HAACUQC69svP555/r008/1YwZM/TTTz9p+vTpGj16tKZPn16k4w4ePFjHjx+3b3v37i3S8QAAgOu49MrO888/rxdffFGdOnWSJNWtW1d79uzRiBEjlJCQoLCwMElSWlqawsPD7e9LS0tT/fr1JUlhYWFKT093OO65c+d05MgR+/sv5O3tLW9v7yKYEQAAKGlcemXn1KlTcnNzLMHd3V25ubmSpKioKIWFhSk5Odm+PyMjQ2vXrlVsbKwkKTY2VseOHdOGDRvsfZYuXarc3FzFxMQUwywAAEBJ5tIrO23bttWbb76pKlWq6Oabb9bGjRs1duxY9ezZU5Jks9k0YMAAvfHGG6pRo4aioqI0ZMgQVapUSe3bt5ck1a5dWy1atFDv3r01depUZWdnq1+/furUqRNPYgEAANeGnYkTJ2rIkCF66qmnlJ6erkqVKukf//iHXn31VXuff/7znzp58qT69OmjY8eOqWnTplq4cKF8fHzsfT799FP169dPzZs3l5ubmzp06KAJEya4YkoAAKCEsZm/f13xdSojI0OBgYE6fvy4AgICXF1Oofz0009q2LChwhLGyTusepGNk5W6U6nTB2jDhg1q0KBBkY0DAMDlXOm/3/xuLAAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGkuDzv79u1T165dFRwcLF9fX9WtW1fr16+37zfG6NVXX1V4eLh8fX0VFxenHTt2OBzjyJEj6tKliwICAhQUFKRevXopMzOzuKcCAABKIJeGnaNHj6pJkyby9PTUggUL9Ntvv2nMmDEqV66cvc+oUaM0YcIETZ06VWvXrlXZsmUVHx+vM2fO2Pt06dJFW7Zs0eLFizVv3jytXLlSffr0ccWUAABACePhysFHjhypiIgIJSUl2duioqLsfzbGaNy4cXrllVfUrl07SdJHH32k0NBQzZkzR506ddLWrVu1cOFCrVu3To0aNZIkTZw4Ua1atdLo0aNVqVKl4p0UAAAoUVx6Zefrr79Wo0aN9MgjjygkJES33nqr3n//ffv+3bt3KzU1VXFxcfa2wMBAxcTEaPXq1ZKk1atXKygoyB50JCkuLk5ubm5au3ZtgeNmZWUpIyPDYQMAANbk0rDzxx9/aMqUKapRo4a+/fZb9e3bV88884ymT58uSUpNTZUkhYaGOrwvNDTUvi81NVUhISEO+z08PFS+fHl7nwuNGDFCgYGB9i0iIsLZUwMAACWES8NObm6uGjRooLfeeku33nqr+vTpo969e2vq1KlFOu7gwYN1/Phx+7Z3794iHQ8AALiOS8NOeHi4oqOjHdpq166tlJQUSVJYWJgkKS0tzaFPWlqafV9YWJjS09Md9p87d05Hjhyx97mQt7e3AgICHDYAAGBNLg07TZo00bZt2xzatm/frsjISEnnFyuHhYUpOTnZvj8jI0Nr165VbGysJCk2NlbHjh3Thg0b7H2WLl2q3NxcxcTEFMMsAABASebSp7GeffZZ3XHHHXrrrbf06KOP6scff9S///1v/fvf/5Yk2Ww2DRgwQG+88YZq1KihqKgoDRkyRJUqVVL79u0lnb8S1KJFC/vtr+zsbPXr10+dOnXiSSwAAODasNO4cWN99dVXGjx4sIYPH66oqCiNGzdOXbp0sff55z//qZMnT6pPnz46duyYmjZtqoULF8rHx8fe59NPP1W/fv3UvHlzubm5qUOHDpowYYIrpgQAAEoYl4YdSWrTpo3atGlz0f02m03Dhw/X8OHDL9qnfPnymjFjRlGUBwAASjmX/7oIAACAokTYAQAAlkbYAQAAlkbYAQAAllaosPPHH384uw4AAIAiUaiwU716dd1zzz365JNPdObMGWfXBAAA4DSFCjs//fST6tWrp+eee05hYWH6xz/+oR9//NHZtQEAAFyzQoWd+vXra/z48dq/f78+/PBDHThwQE2bNlWdOnU0duxYHTx40Nl1AgAAFMo1LVD28PDQQw89pNmzZ2vkyJHauXOnBg0apIiICD3++OM6cOCAs+oEAAAolGsKO+vXr9dTTz2l8PBwjR07VoMGDdKuXbu0ePFi7d+/X+3atXNWnQAAAIVSqF8XMXbsWCUlJWnbtm1q1aqVPvroI7Vq1UpubuezU1RUlKZNm6aqVas6s1YAAICrVqiwM2XKFPXs2VPdu3dXeHh4gX1CQkL0wQcfXFNxAAAA16pQYWfHjh2X7ePl5aWEhITCHB4AAMBpChV2kpKS5Ofnp0ceecShffbs2Tp16hQh5zqwdevWYhmnQoUKqlKlSrGMBQCwpkKFnREjRui9997L1x4SEqI+ffoQdiwsJ/OoZLOpa9euxTKej28Zbft9K4EHAFBohQo7KSkpioqKytceGRmplJSUay4KJVduVqZkjILbDJRncESRjpV9eK8OzxujQ4cOEXYAAIVWqLATEhKizZs353va6ueff1ZwcLAz6kIJ5xkcIe+w6q4uAwCAyyrU9+x07txZzzzzjJYtW6acnBzl5ORo6dKl6t+/vzp16uTsGgEAAAqtUFd2Xn/9df35559q3ry5PDzOHyI3N1ePP/643nrrLacWCAAAcC0KFXa8vLz02Wef6fXXX9fPP/8sX19f1a1bV5GRkc6uDwAA4JoUKuzkuemmm3TTTTc5qxYAAACnK1TYycnJ0bRp05ScnKz09HTl5uY67F+6dKlTigMAALhWhQo7/fv317Rp09S6dWvVqVNHNpvN2XUBAAA4RaHCzqxZs/T555+rVatWzq4HAADAqQr16LmXl5eqV+c7VgAAQMlXqLAzcOBAjR8/XsYYZ9cDAADgVIW6jbVq1SotW7ZMCxYs0M033yxPT0+H/V9++aVTigMAALhWhQo7QUFBevDBB51dCwAAgNMVKuwkJSU5uw4AAIAiUag1O5J07tw5LVmyRO+9955OnDghSdq/f78yMzOdVhwAAMC1KtSVnT179qhFixZKSUlRVlaW7rvvPvn7+2vkyJHKysrS1KlTnV0nAABAoRTqyk7//v3VqFEjHT16VL6+vvb2Bx98UMnJyU4rDgAA4FoV6srOd999px9++EFeXl4O7VWrVtW+ffucUhgAAIAzFOrKTm5urnJycvK1//XXX/L397/mogAAAJylUGHn/vvv17hx4+yvbTabMjMzNXToUH6FBAAAKFEKdRtrzJgxio+PV3R0tM6cOaPHHntMO3bsUIUKFTRz5kxn1wgAAFBohQo7lStX1s8//6xZs2Zp8+bNyszMVK9evdSlSxeHBcsAAACuVqiwI0keHh7q2rWrM2sBAABwukKFnY8++uiS+x9//PFCFQMAAOBshQo7/fv3d3idnZ2tU6dOycvLS2XKlCHsAACAEqNQT2MdPXrUYcvMzNS2bdvUtGlTFigDAIASpdC/G+tCNWrU0Ntvv53vqg8AAIArOS3sSOcXLe/fv9+ZhwQAALgmhVqz8/XXXzu8NsbowIEDmjRpkpo0aeKUwgAAAJyhUGGnffv2Dq9tNpsqVqyoe++9V2PGjHFGXQAAAE5RqLCTm5vr7DoAAACKhFPX7AAAAJQ0hbqy89xzz11x37FjxxZmCAAAAKcoVNjZuHGjNm7cqOzsbNWsWVOStH37drm7u6tBgwb2fjabzTlVAgAAFFKhwk7btm3l7++v6dOnq1y5cpLOf9Fgjx491KxZMw0cONCpRQIAABRWodbsjBkzRiNGjLAHHUkqV66c3njjDZ7GAgAAJUqhwk5GRoYOHjyYr/3gwYM6ceLENRcFAADgLIUKOw8++KB69OihL7/8Un/99Zf++usv/fe//1WvXr300EMPObtGAACAQivUmp2pU6dq0KBBeuyxx5SdnX3+QB4e6tWrl9555x2nFggAAHAtChV2ypQpo3/961965513tGvXLklStWrVVLZsWacWBwAAcK2u6UsFDxw4oAMHDqhGjRoqW7asjDHOqgsAAMApChV2Dh8+rObNm+umm25Sq1atdODAAUlSr169eOwcAACUKIUKO88++6w8PT2VkpKiMmXK2Ns7duyohQsXOq04AACAa1WoNTuLFi3St99+q8qVKzu016hRQ3v27HFKYQAAAM5QqCs7J0+edLiik+fIkSPy9va+5qIAAACcpVBhp1mzZvroo4/sr202m3JzczVq1Cjdc889TisOAADgWhXqNtaoUaPUvHlzrV+/XmfPntU///lPbdmyRUeOHNH333/v7BoBAAAKrVBXdurUqaPt27eradOmateunU6ePKmHHnpIGzduVLVq1ZxdIwAAQKFd9ZWd7OxstWjRQlOnTtXLL79cFDUBAAA4zVVf2fH09NTmzZuLohYAAACnK9RtrK5du+qDDz5waiFvv/22bDabBgwYYG87c+aMEhMTFRwcLD8/P3Xo0EFpaWkO70tJSVHr1q1VpkwZhYSE6Pnnn9e5c+ecWhsAACi9CrVA+dy5c/rwww+1ZMkSNWzYMN/vxBo7duxVHW/dunV67733VK9ePYf2Z599Vt98841mz56twMBA9evXTw899JB9EXROTo5at26tsLAw/fDDDzpw4IAef/xxeXp66q233irM1AAAgMVcVdj5448/VLVqVf36669q0KCBJGn79u0OfWw221UVkJmZqS5duuj999/XG2+8YW8/fvy4PvjgA82YMUP33nuvJCkpKUm1a9fWmjVrdPvtt2vRokX67bfftGTJEoWGhqp+/fp6/fXX9cILL2jYsGHy8vK6qloAAID1XNVtrBo1aujQoUNatmyZli1bppCQEM2aNcv+etmyZVq6dOlVFZCYmKjWrVsrLi7OoX3Dhg3Kzs52aK9Vq5aqVKmi1atXS5JWr16tunXrKjQ01N4nPj5eGRkZ2rJly0XHzMrKUkZGhsMGAACs6aqu7Fz4W80XLFigkydPFnrwWbNm6aefftK6devy7UtNTZWXl5eCgoIc2kNDQ5Wammrv8/egk7c/b9/FjBgxQq+99lqh6wYAAKVHoRYo57kw/FyNvXv3qn///vr000/l4+NzLWVctcGDB+v48eP2be/evcU6PgAAKD5XFXZsNlu+NTlXu0Ynz4YNG5Senq4GDRrIw8NDHh4eWrFihSZMmCAPDw+Fhobq7NmzOnbsmMP70tLSFBYWJkkKCwvL93RW3uu8PgXx9vZWQECAwwYAAKzpqm9jde/e3f7LPs+cOaMnn3wy39NYX3755WWP1bx5c/3yyy8ObT169FCtWrX0wgsvKCIiQp6enkpOTlaHDh0kSdu2bVNKSopiY2MlSbGxsXrzzTeVnp6ukJAQSdLixYsVEBCg6Ojoq5kaAACwqKsKOwkJCQ6vu3btWuiB/f39VadOHYe2smXLKjg42N7eq1cvPffccypfvrwCAgL09NNPKzY2Vrfffrsk6f7771d0dLS6deumUaNGKTU1Va+88ooSExP57esAAEDSVYadpKSkoqqjQO+++67c3NzUoUMHZWVlKT4+Xv/617/s+93d3TVv3jz17dtXsbGxKlu2rBISEjR8+PBirRMAAJRchfpSwaKyfPlyh9c+Pj6aPHmyJk+efNH3REZGav78+UVcGQAAKK2u6WksAACAko6wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALM3D1QVYXUpKig4dOlTk42zdurXIxwAAoDQi7BShlJQU1axVW2dOn3J1KQAAXLcIO0Xo0KFDOnP6lILbDJRncESRjnX6j/U6/t0nRToGAAClEWGnGHgGR8g7rHqRjpF9eG+RHh8AgNKKBcoAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSXBp2RowYocaNG8vf318hISFq3769tm3b5tDnzJkzSkxMVHBwsPz8/NShQwelpaU59ElJSVHr1q1VpkwZhYSE6Pnnn9e5c+eKcyoAAKCEcmnYWbFihRITE7VmzRotXrxY2dnZuv/++3Xy5El7n2effVb/+9//NHv2bK1YsUL79+/XQw89ZN+fk5Oj1q1b6+zZs/rhhx80ffp0TZs2Ta+++qorpgQAAEoYD1cOvnDhQofX06ZNU0hIiDZs2KA777xTx48f1wcffKAZM2bo3nvvlSQlJSWpdu3aWrNmjW6//XYtWrRIv/32m5YsWaLQ0FDVr19fr7/+ul544QUNGzZMXl5erpgaAAAoIUrUmp3jx49LksqXLy9J2rBhg7KzsxUXF2fvU6tWLVWpUkWrV6+WJK1evVp169ZVaGiovU98fLwyMjK0ZcuWYqweAACURC69svN3ubm5GjBggJo0aaI6depIklJTU+Xl5aWgoCCHvqGhoUpNTbX3+XvQyduft68gWVlZysrKsr/OyMhw1jQAAEAJU2Ku7CQmJurXX3/VrFmzinysESNGKDAw0L5FREQU+ZgAAMA1SkTY6devn+bNm6dly5apcuXK9vawsDCdPXtWx44dc+iflpamsLAwe58Ln87Ke53X50KDBw/W8ePH7dvevXudOBsAAFCSuDTsGGPUr18/ffXVV1q6dKmioqIc9jds2FCenp5KTk62t23btk0pKSmKjY2VJMXGxuqXX35Renq6vc/ixYsVEBCg6OjoAsf19vZWQECAwwYAAKzJpWt2EhMTNWPGDM2dO1f+/v72NTaBgYHy9fVVYGCgevXqpeeee07ly5dXQECAnn76acXGxur222+XJN1///2Kjo5Wt27dNGrUKKWmpuqVV15RYmKivL29XTk9AABQArg07EyZMkWSdPfddzu0JyUlqXv37pKkd999V25uburQoYOysrIUHx+vf/3rX/a+7u7umjdvnvr27avY2FiVLVtWCQkJGj58eHFNAwAAlGAuDTvGmMv28fHx0eTJkzV58uSL9omMjNT8+fOdWRoAALCIErFAGQAAoKgQdgAAgKURdgAAgKURdgAAgKURdgAAgKURdgAAgKURdgAAgKURdgAAgKURdgAAgKURdgAAgKW59NdFAFdi69atRT5GhQoVVKVKlSIfBwBQ/Ag7KLFyMo9KNpu6du1a5GP5+JbRtt+3EngAwIIIOyixcrMyJWMU3GagPIMjimyc7MN7dXjeGB06dIiwAwAWRNhBiecZHCHvsOquLgMAUEqxQBkAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFiah6sLAEqKrVu3Fss4FSpUUJUqVYplLAAAYQdQTuZRyWZT165di2U8H98y2vb7VgIPABQTwg6ue7lZmZIxCm4zUJ7BEUU6VvbhvTo8b4wOHTpE2AGAYkLYAf6PZ3CEvMOqu7oMAICTsUAZAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYmoerCwCuR1u3bi3yMSpUqKAqVaoU+TgAUNIRdoBilJN5VLLZ1LVr1yIfy8e3jLb9vpXAA+C6R9gBilFuVqZkjILbDJRncESRjZN9eK8Ozxuj7777TrVr1y6ycfJkZWXJ29u7yMfhahWAwiDsAC7gGRwh77DqRXb84ryCJEmyuUkmt8iH4WoVgMKwTNiZPHmy3nnnHaWmpuqWW27RxIkTddttt7m6LMAliusKkiSd/mO9jn/3SbFdrTp06BBhB8BVsUTY+eyzz/Tcc89p6tSpiomJ0bhx4xQfH69t27YpJCTE1eUBLlPUV5Ck8yGkuMYCgMKwRNgZO3asevfurR49ekiSpk6dqm+++UYffvihXnzxRRdXB8CZiuNJNon1QYCVlPqwc/bsWW3YsEGDBw+2t7m5uSkuLk6rV692YWUAnKm41yEV1/qglJQUHTp0qEjHyMNC8tKBz4Tzlfqwc+jQIeXk5Cg0NNShPTQ0VL///nuB78nKylJWVpb99fHjxyVJGRkZTq0tMzPz/HipO5V79oxTj32hvFsJRT1WcY1TnGMxp9IxVtb+rZIxCmj8kNwDKxbZOJKUc/ygMtZ9qW+//VY1a9YssnHS0tLUtdvjOptVtOfo/7NJMkU+ipe3jz75+KN8/10uCm5ubsrNLfrF8cU1llU/E94+vtqwfp0iIpy7ri/v321jLjMHU8rt27fPSDI//PCDQ/vzzz9vbrvttgLfM3ToUKPzZ5eNjY2NjY2tlG979+69ZFYo9Vd2KlSoIHd3d6WlpTm0p6WlKSwsrMD3DB48WM8995z9dW5uro4cOaLg4GDZbLZrqicjI0MRERHau3evAgICrulYJZXV52j1+UnM0SqYY+ln9flJRTtHY4xOnDihSpUqXbJfqQ87Xl5eatiwoZKTk9W+fXtJ58NLcnKy+vXrV+B7vL29892jDAoKcmpdAQEBlv3g5rH6HK0+P4k5WgVzLP2sPj+p6OYYGBh42T6lPuxI0nPPPaeEhAQ1atRIt912m8aNG6eTJ0/an84CAADXL0uEnY4dO+rgwYN69dVXlZqaqvr162vhwoXFsjgOAACUbJYIO5LUr1+/i962Kk7e3t4aOnRosTzK5ypWn6PV5ycxR6tgjqWf1ecnlYw52oy53PNaAAAApZebqwsAAAAoSoQdAABgaYQdAABgaYQdAABgaYQdJ5o8ebKqVq0qHx8fxcTE6Mcff3R1SYU2bNgw2Ww2h61WrVr2/WfOnFFiYqKCg4Pl5+enDh065PsW65Jm5cqVatu2rSpVqiSbzaY5c+Y47DfG6NVXX1V4eLh8fX0VFxenHTt2OPQ5cuSIunTpooCAAAUFBalXr17234FWElxujt27d893Xlu0aOHQpyTPccSIEWrcuLH8/f0VEhKi9u3ba9u2bQ59ruSzmZKSotatW6tMmTIKCQnR888/r3PnzhXnVC7qSuZ499135zuPTz75pEOfkjrHKVOmqF69evYvmIuNjdWCBQvs+0v7+ZMuP8fSfP4u5u2335bNZtOAAQPsbSXqXDrlF1TBzJo1y3h5eZkPP/zQbNmyxfTu3dsEBQWZtLQ0V5dWKEOHDjU333yzOXDggH07ePCgff+TTz5pIiIiTHJyslm/fr25/fbbzR133OHCii9v/vz55uWXXzZffvmlkWS++uorh/1vv/22CQwMNHPmzDE///yzeeCBB0xUVJQ5ffq0vU+LFi3MLbfcYtasWWO+++47U716ddO5c+dinsnFXW6OCQkJpkWLFg7n9ciRIw59SvIc4+PjTVJSkvn111/Npk2bTKtWrUyVKlVMZmamvc/lPpvnzp0zderUMXFxcWbjxo1m/vz5pkKFCmbw4MGumFI+VzLHu+66y/Tu3dvhPB4/fty+vyTP8euvvzbffPON2b59u9m2bZt56aWXjKenp/n111+NMaX//Blz+TmW5vNXkB9//NFUrVrV1KtXz/Tv39/eXpLOJWHHSW677TaTmJhof52Tk2MqVapkRowY4cKqCm/o0KHmlltuKXDfsWPHjKenp5k9e7a9bevWrUaSWb16dTFVeG0uDAK5ubkmLCzMvPPOO/a2Y8eOGW9vbzNz5kxjjDG//fabkWTWrVtn77NgwQJjs9nMvn37iq32K3WxsNOuXbuLvqe0zTE9Pd1IMitWrDDGXNlnc/78+cbNzc2kpqba+0yZMsUEBASYrKys4p3AFbhwjsac/8fy7/+oXKi0zbFcuXLmP//5jyXPX568ORpjrfN34sQJU6NGDbN48WKHeZW0c8ltLCc4e/asNmzYoLi4OHubm5ub4uLitHr1ahdWdm127NihSpUq6cYbb1SXLl2UkpIiSdqwYYOys7Md5lurVi1VqVKl1M539+7dSk1NdZhTYGCgYmJi7HNavXq1goKC1KhRI3ufuLg4ubm5ae3atcVec2EtX75cISEhqlmzpvr27avDhw/b95W2OR4/flySVL58eUlX9tlcvXq16tat6/AN6/Hx8crIyNCWLVuKsforc+Ec83z66aeqUKGC6tSpo8GDB+vUqVP2faVljjk5OZo1a5ZOnjyp2NhYS56/C+eYxwrnT5ISExPVunVrh3Mmlby/i5b5BmVXOnTokHJycvL9eorQ0FD9/vvvLqrq2sTExGjatGmqWbOmDhw4oNdee03NmjXTr7/+qtTUVHl5eeX75amhoaFKTU11TcHXKK/ugs5h3r7U1FSFhIQ47Pfw8FD58uVLzbxbtGihhx56SFFRUdq1a5deeukltWzZUqtXr5a7u3upmmNubq4GDBigJk2aqE6dOpJ0RZ/N1NTUAs9z3r6SpKA5StJjjz2myMhIVapUSZs3b9YLL7ygbdu26csvv5RU8uf4yy+/KDY2VmfOnJGfn5+++uorRUdHa9OmTZY5fxebo1T6z1+eWbNm6aefftK6devy7StpfxcJOyhQy5Yt7X+uV6+eYmJiFBkZqc8//1y+vr4urAzXolOnTvY/161bV/Xq1VO1atW0fPlyNW/e3IWVXb3ExET9+uuvWrVqlatLKTIXm2OfPn3sf65bt67Cw8PVvHlz7dq1S9WqVSvuMq9azZo1tWnTJh0/flxffPGFEhIStGLFCleX5VQXm2N0dHSpP3+StHfvXvXv31+LFy+Wj4+Pq8u5LG5jOUGFChXk7u6eb5V5WlqawsLCXFSVcwUFBemmm27Szp07FRYWprNnz+rYsWMOfUrzfPPqvtQ5DAsLU3p6usP+c+fO6ciRI6V23jfeeKMqVKignTt3Sio9c+zXr5/mzZunZcuWqXLlyvb2K/lshoWFFXie8/aVFBebY0FiYmIkyeE8luQ5enl5qXr16mrYsKFGjBihW265RePHj7fU+bvYHAtS2s6fdP42VXp6uho0aCAPDw95eHhoxYoVmjBhgjw8PBQaGlqiziVhxwm8vLzUsGFDJScn29tyc3OVnJzscI+2NMvMzNSuXbsUHh6uhg0bytPT02G+27ZtU0pKSqmdb1RUlMLCwhzmlJGRobVr19rnFBsbq2PHjmnDhg32PkuXLlVubq79P1alzV9//aXDhw8rPDxcUsmfozFG/fr101dffaWlS5cqKirKYf+VfDZjY2P1yy+/OIS6xYsXKyAgwH6bwZUuN8eCbNq0SZIczmNJnuOFcnNzlZWVZYnzdzF5cyxIaTx/zZs31y+//KJNmzbZt0aNGqlLly72P5eoc+nU5c7XsVmzZhlvb28zbdo089tvv5k+ffqYoKAgh1XmpcnAgQPN8uXLze7du833339v4uLiTIUKFUx6erox5vwjhVWqVDFLly4169evN7GxsSY2NtbFVV/aiRMnzMaNG83GjRuNJDN27FizceNGs2fPHmPM+UfPg4KCzNy5c83mzZtNu3btCnz0/NZbbzVr1641q1atMjVq1Cgxj2Ubc+k5njhxwgwaNMisXr3a7N692yxZssQ0aNDA1KhRw5w5c8Z+jJI8x759+5rAwECzfPlyh8d2T506Ze9zuc9m3uOu999/v9m0aZNZuHChqVixYol5rPdyc9y5c6cZPny4Wb9+vdm9e7eZO3euufHGG82dd95pP0ZJnuOLL75oVqxYYXbv3m02b95sXnzxRWOz2cyiRYuMMaX//Blz6TmW9vN3KRc+ZVaSziVhx4kmTpxoqlSpYry8vMxtt91m1qxZ4+qSCq1jx44mPDzceHl5mRtuuMF07NjR7Ny5077/9OnT5qmnnjLlypUzZcqUMQ8++KA5cOCACyu+vGXLlhlJ+baEhARjzPnHz4cMGWJCQ0ONt7e3ad68udm2bZvDMQ4fPmw6d+5s/Pz8TEBAgOnRo4c5ceKEC2ZTsEvN8dSpU+b+++83FStWNJ6eniYyMtL07t07XyAvyXMsaG6STFJSkr3PlXw2//zzT9OyZUvj6+trKlSoYAYOHGiys7OLeTYFu9wcU1JSzJ133mnKly9vvL29TfXq1c3zzz/v8D0txpTcOfbs2dNERkYaLy8vU7FiRdO8eXN70DGm9J8/Yy49x9J+/i7lwrBTks6lzRhjnHutCAAAoORgzQ4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AlCDLly+XzWbL9zuFABQeYQfARR08eFB9+/ZVlSpV5O3trbCwMMXHx+v777+396latapsNptmzZqV7/0333yzbDabpk2b5tB/3LhxF339d3/++adsNluB25o1ayRJOTk5evvtt1WrVi35+vqqfPnyiomJ0X/+85+LzqukBIq7775bAwYMcGkNwPXAw9UFACi5OnTooLNnz2r69Om68cYblZaWpuTkZB0+fNihX0REhJKSktSpUyd725o1a5SamqqyZctecx1LlizRzTff7NAWHBwsSXrttdf03nvvadKkSWrUqJEyMjK0fv16HT169JrHBWANXNkBUKBjx47pu+++08iRI3XPPfcoMjJSt912mwYPHqwHHnjAoW+XLl20YsUK7d2719724YcfqkuXLvLwuPb/pwoODlZYWJjD5unpKUn6+uuv9dRTT+mRRx5RVFSUbrnlFvXq1UuDBg0q9HhZWVkaNGiQbrjhBpUtW1YxMTFavny5ff+0adMUFBSkb7/9VrVr15afn59atGihAwcO2PucO3dOzzzzjIKCghQcHKwXXnhBCQkJat++vSSpe/fuWrFihcaPH2+/WvXnn3/a379hwwY1atRIZcqU0R133KFt27YVej7A9Y6wA6BAfn5+8vPz05w5c5SVlXXJvqGhoYqPj9f06dMlSadOndJnn32mnj17FnmdYWFhWrp0qQ4ePOi0Y/br10+rV6/WrFmztHnzZj3yyCNq0aKFduzYYe9z6tQpjR49Wh9//LFWrlyplJQUh4A1cuRIffrpp0pKStL333+vjIwMzZkzx75//Pjxio2NVe/evXXgwAEdOHBAERER9v0vv/yyxowZo/Xr18vDw6NYfpaAVRF2ABTIw8ND06ZN0/Tp0xUUFKQmTZropZde0ubNmwvs37NnT02bNk3GGH3xxReqVq2a6tev75Ra7rjjDnv4ytvyjB07VgcPHlRYWJjq1aunJ598UgsWLCj0WCkpKUpKStLs2bPVrFkzVatWTYMGDVLTpk2VlJRk75edna2pU6eqUaNGatCggfr166fk5GT7/okTJ2rw4MF68MEHVatWLU2aNElBQUH2/YGBgfLy8lKZMmXsV6vc3d3t+998803dddddio6O1osvvqgffvhBZ86cKfS8gOsZYQfARXXo0EH79+/X119/rRYtWmj58uVq0KCBw4LjPK1bt1ZmZqZWrlypDz/80KlXIj777DNt2rTJYcsTHR2tX3/9VWvWrFHPnj2Vnp6utm3b6oknnijUWL/88otycnJ00003OYSrFStWaNeuXfZ+ZcqUUbVq1eyvw8PDlZ6eLkk6fvy40tLSdNttt9n3u7u7q2HDhldcR7169RyOLcl+fABXhwXKAC7Jx8dH9913n+677z4NGTJETzzxhIYOHaru3bs79PPw8FC3bt00dOhQrV27Vl999ZXTaoiIiFD16tUvut/NzU2NGzdW48aNNWDAAH3yySfq1q2bXn75ZUVFRV3VWJmZmXJ3d9eGDRscrrRIcriilLdmKI/NZpMx5qrGupS/H99ms0mScnNznXZ84HrClR0AVyU6OlonT54scF/Pnj21YsUKtWvXTuXKlSvmyv6/6OhoSbponZdy6623KicnR+np6apevbrDFhYWdkXHCAwMVGhoqNatW2dvy8nJ0U8//eTQz8vLSzk5OVddI4Crw5UdAAU6fPiwHnnkEfXs2VP16tWTv7+/1q9fr1GjRqldu3YFvqd27do6dOiQypQpc1Vj7du3z+HWlCRFRkY61JKamuqwPygoSD4+Pnr44YfVpEkT3XHHHQoLC9Pu3bs1ePBg3XTTTapVq9Ylx/3ll1/k7+9vf22z2XTLLbeoS5cuevzxxzVmzBjdeuutOnjwoJKTk1WvXj21bt36iub09NNPa8SIEapevbpq1aqliRMn6ujRo/arNNL57xhau3at/vzzT/n5+al8+fJXdGwAV4ewA6BAfn5+iomJ0bvvvqtdu3YpOztbERER6t27t1566aWLvi/v+2+uxujRozV69GiHto8//lhNmzaVJMXFxeV7z8yZM9WpUyfFx8dr5syZGjFihI4fP66wsDDde++9GjZs2GUfe7/zzjsdXru7u+vcuXNKSkrSG2+8oYEDB2rfvn2qUKGCbr/9drVp0+aK5/TCCy8oNTVVjz/+uNzd3dWnTx/Fx8c73BobNGiQEhISFB0drdOnT2v37t1XfHwAV85mnHmTGQBQoNzcXNWuXVuPPvqoXn/9dVeXA1xXuLIDAEVgz549WrRoke666y5lZWVp0qRJ2r17tx577DFXlwZcd1igDABFwM3NTdOmTVPjxo3VpEkT/fLLL1qyZIlq167t6tKA6w63sQAAgKVxZQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFja/wOOXfCcaBMVngAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_smiles = ''.join(df['smiles'])\n",
        "tokens = [char for char in all_smiles]\n",
        "\n",
        "# Calculate the frequency of each token\n",
        "token_counts = Counter(tokens)\n",
        "\n",
        "# Display a bar chart of token diversity\n",
        "plt.bar(token_counts.keys(), token_counts.values())\n",
        "plt.title('Token Diversity in SMILES')\n",
        "plt.xlabel('Token')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rA_URMdEWg4K",
        "outputId": "48f5c82e-7877-45ec-ef4a-49e3a55e6bfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fully Connected(Baseline)"
      ],
      "metadata": {
        "id": "iszZDIzALBLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X = encoded_df.iloc[:, :-1].values\n",
        "y = encoded_df.iloc[:, -1].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train.reshape(-1, 1))\n",
        "X_test = scaler.transform(X_test.reshape(-1, 1))\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "X_train_tensor = X_train_tensor.view(-1, 39)\n",
        "X_test_tensor = X_test_tensor.view(-1, 39)\n",
        "\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 128)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(64, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu1(self.fc1(x))\n",
        "        x = self.relu2(self.fc2(x))\n",
        "        x = self.sigmoid(self.fc3(x))\n",
        "        return x\n",
        "\n",
        "model = SimpleNN(input_size=39)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "\n",
        "    # Training loop\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels.view(-1, 1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        y_train_pred = (model(X_train_tensor) > 0.5).float().numpy()\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}, Train Accuracy: {train_accuracy * 100:.2f}%')\n",
        "\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    y_pred = (model(X_test_tensor) > 0.5).float().numpy()\n",
        "\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZH9o27HsUY6",
        "outputId": "d1a0db7e-eb6e-4693-ec67-58ae4928eb1e"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Train Accuracy: 83.78%\n",
            "Epoch 2/10, Train Accuracy: 87.20%\n",
            "Epoch 3/10, Train Accuracy: 87.01%\n",
            "Epoch 4/10, Train Accuracy: 87.80%\n",
            "Epoch 5/10, Train Accuracy: 88.41%\n",
            "Epoch 6/10, Train Accuracy: 88.41%\n",
            "Epoch 7/10, Train Accuracy: 88.78%\n",
            "Epoch 8/10, Train Accuracy: 88.05%\n",
            "Epoch 9/10, Train Accuracy: 89.02%\n",
            "Epoch 10/10, Train Accuracy: 89.76%\n",
            "Test Accuracy: 86.83%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ز"
      ],
      "metadata": {
        "id": "RpE-cyaEg8Wf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Assuming 'encoded_df' is your dataframe\n",
        "X = encoded_df.iloc[:, :-1].values\n",
        "y = encoded_df.iloc[:, -1].values\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Calculate the sum of each column in X_test before scaling\n",
        "column_sums = np.sum(X_test, axis=1)\n",
        "\n",
        "# Divide data into 10 bins\n",
        "hist_values, bin_edges = np.histogram(column_sums, bins=10)\n",
        "\n",
        "# Assign each data point in X_test to a bin\n",
        "bin_indices = np.digitize(column_sums, bins=bin_edges, right=True)\n",
        "\n",
        "# Initialize a list to store DataLoader for each bin\n",
        "bin_loaders = []\n",
        "\n",
        "# Iterate over each bin and evaluate the model on datasets of each bin\n",
        "# Iterate over each bin and evaluate the model on datasets of each bin\n",
        "for bin_id in range(1, 11):  # Bins are indexed from 1 to 10\n",
        "    # Select data points in the current bin\n",
        "    bin_X_test = X_test[bin_indices == bin_id]\n",
        "    bin_y_test = y_test[bin_indices == bin_id]\n",
        "\n",
        "    # Check if the bin is not empty before standardizing\n",
        "    if bin_X_test.shape[0] > 0:\n",
        "        # Standardize the data using the scaler fitted on X_train\n",
        "        bin_X_test = scaler.transform(bin_X_test.reshape(-1, 1)).reshape(-1, X_test.shape[1])\n",
        "\n",
        "        # Convert to PyTorch tensors\n",
        "        bin_X_test_tensor = torch.tensor(bin_X_test, dtype=torch.float32)\n",
        "        bin_y_test_tensor = torch.tensor(bin_y_test, dtype=torch.float32)\n",
        "\n",
        "        # Create a DataLoader for the current bin\n",
        "        bin_dataset = TensorDataset(bin_X_test_tensor, bin_y_test_tensor)\n",
        "        bin_loader = DataLoader(bin_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "        # Evaluate the model on the current bin\n",
        "        model.eval()\n",
        "        all_predictions_bin = []\n",
        "        all_labels_bin = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs_bin, labels_bin in bin_loader:\n",
        "                outputs_bin = model(inputs_bin)\n",
        "                predictions_bin = (outputs_bin > 0.5).float().numpy()\n",
        "                all_predictions_bin.extend(predictions_bin)\n",
        "                all_labels_bin.extend(labels_bin.numpy())\n",
        "\n",
        "        # Calculate test accuracy for the current bin\n",
        "        test_accuracy_bin = accuracy_score(all_labels_bin, all_predictions_bin)\n",
        "        print(f'Bin {bin_id}/10, Test Accuracy: {test_accuracy_bin * 100:.2f}%')\n",
        "        bin_loaders.append(bin_loader)\n",
        "    else:\n",
        "        print(f'Bin {bin_id}/10 is empty. Skipping evaluation.')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76RQdyNng_tS",
        "outputId": "c9d633dd-d020-4ae0-df28-23f82ee2961c"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bin 1/10, Test Accuracy: 83.23%\n",
            "Bin 2/10, Test Accuracy: 89.95%\n",
            "Bin 3/10, Test Accuracy: 80.85%\n",
            "Bin 4/10, Test Accuracy: 100.00%\n",
            "Bin 5/10, Test Accuracy: 100.00%\n",
            "Bin 6/10, Test Accuracy: 100.00%\n",
            "Bin 7/10 is empty. Skipping evaluation.\n",
            "Bin 8/10 is empty. Skipping evaluation.\n",
            "Bin 9/10 is empty. Skipping evaluation.\n",
            "Bin 10/10, Test Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LSTM"
      ],
      "metadata": {
        "id": "b0OR79E37xXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define a list of SMILES symbols\n",
        "smiles_symbols = ['C', 'N', 'O', 'P', 'S', 'F', 'Cl', 'Br', 'I', 'H', 'B', 'Si', ' ', '(', ')', '=', '#', '1', '2', '3', '4', '5', '6', '7', '8', '9', '0', '+', '-', '[', ']', '@', '%', '.', '/']\n",
        "\n",
        "# Function to tokenize a SMILES string and create one-hot encodings\n",
        "def tokenize_smiles(smiles):\n",
        "    tokens = []\n",
        "    i = 0\n",
        "    while i < len(smiles):\n",
        "        char = smiles[i]\n",
        "        if char in smiles_symbols:\n",
        "            # Check if the next character forms a two-character element\n",
        "            potential_element = char + smiles[i + 1] if i + 1 < len(smiles) else None\n",
        "            if potential_element in smiles_symbols:\n",
        "                tokens.append(smiles_symbols.index(potential_element))\n",
        "                i += 2  # Skip the next character for a two-character element\n",
        "            else:\n",
        "                tokens.append(smiles_symbols.index(char))\n",
        "                i += 1\n",
        "        else:\n",
        "            # Handle other characters (non-SMILES symbols)\n",
        "            tokens.append(len(smiles_symbols))  # Assign a special index for non-SMILES symbols\n",
        "            i += 1\n",
        "    return tokens\n",
        "\n",
        "# Function to convert a list of SMILES strings to a list of one-hot encoded vectors\n",
        "def encode_smiles_strings(smiles_strings):\n",
        "    encoded_list = []\n",
        "    for smiles_string in smiles_strings:\n",
        "        tokenized_smiles = tokenize_smiles(smiles_string)\n",
        "        one_hot_encoding = np.zeros((len(tokenized_smiles), len(smiles_symbols) + 1))  # +1 for the special index\n",
        "        for i, token in enumerate(tokenized_smiles):\n",
        "            one_hot_encoding[i, token] = 1\n",
        "        encoded_list.append(one_hot_encoding)\n",
        "    return encoded_list\n",
        "\n",
        "# PyTorch dataset class for SMILES data\n",
        "class SMILESDataset(Dataset):\n",
        "    def __init__(self, smiles_list, labels):\n",
        "        self.smiles_list = smiles_list\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.smiles_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.smiles_list[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.float32)\n",
        "\n",
        "# LSTM model for classification\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        flattened = self.flatten(lstm_out[:, -1, :])  # Take the output of the last time step\n",
        "        output = self.sigmoid(self.fc(flattened))\n",
        "        return output\n",
        "\n",
        "# Read CSV file and extract SMILES strings and labels\n",
        "csv_file_path = 'BBBP.csv'  # Replace with the actual path to your CSV file\n",
        "df = pd.read_csv(csv_file_path)\n",
        "smiles_column = df.iloc[:, 3]\n",
        "labels = df.iloc[:, 2].values  # Assuming labels are in the third column\n",
        "\n",
        "# Tokenize and encode SMILES strings\n",
        "encoded_smiles_list = encode_smiles_strings(smiles_column)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(encoded_smiles_list, labels, test_size = 0.2, random_state = 0)\n",
        "train_dataset = SMILESDataset(X_train, y_train)\n",
        "test_dataset = SMILESDataset(X_test, y_test)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "# Instantiate the LSTM model\n",
        "input_size = len(smiles_symbols) + 1  # +1 for the special index\n",
        "hidden_size = 64\n",
        "num_layers = 2\n",
        "output_size = 1\n",
        "model = LSTMModel(input_size, hidden_size, num_layers, output_size)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n"
      ],
      "metadata": {
        "id": "wfqhd0Lzy2Oi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "\n",
        "    # Training loop\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels.view(-1, 1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Calculate training accuracy after each epoch\n",
        "    with torch.no_grad():\n",
        "          model.eval()\n",
        "          all_predictions = []\n",
        "          all_labels = []\n",
        "          for inputs, labels in train_loader:\n",
        "             outputs = model(inputs)\n",
        "             predictions = (outputs > 0.5).float().numpy()\n",
        "             all_predictions.extend(predictions)\n",
        "             all_labels.extend(labels.numpy())\n",
        "    train_accuracy = accuracy_score(all_labels, all_predictions)\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}, Train Accuracy: {train_accuracy * 100:.2f}%')\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    for inputs, labels in test_loader:\n",
        "        outputs = model(inputs)\n",
        "        predictions = (outputs > 0.5).float().numpy()\n",
        "        all_predictions.extend(predictions)\n",
        "        all_labels.extend(labels.numpy())\n",
        "\n",
        "# Calculate test accuracy\n",
        "test_accuracy = accuracy_score(all_labels, all_predictions)\n",
        "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acn8pBSWzQMV",
        "outputId": "c97f71a9-f54d-4a5d-c030-599e85b82554"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Train Accuracy: 83.35%\n",
            "Epoch 2/10, Train Accuracy: 87.80%\n",
            "Epoch 3/10, Train Accuracy: 87.07%\n",
            "Epoch 4/10, Train Accuracy: 89.57%\n",
            "Epoch 5/10, Train Accuracy: 88.84%\n",
            "Epoch 6/10, Train Accuracy: 90.91%\n",
            "Epoch 7/10, Train Accuracy: 90.91%\n",
            "Epoch 8/10, Train Accuracy: 91.95%\n",
            "Epoch 9/10, Train Accuracy: 89.27%\n",
            "Epoch 10/10, Train Accuracy: 91.83%\n",
            "Test Accuracy: 87.07%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ز"
      ],
      "metadata": {
        "id": "r1UfLiHxeV-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ... (Rest of the code remains unchanged)\n",
        "\n",
        "# Function to calculate the length of SMILES strings\n",
        "def calculate_smiles_length(smiles):\n",
        "    return len(smiles)\n",
        "\n",
        "# Add a column for SMILES lengths to the DataFrame\n",
        "df['SMILES_Length'] = df['smiles'].apply(calculate_smiles_length)\n",
        "\n",
        "# Create 10 bins based on the SMILES lengths\n",
        "df['Bin'] = pd.qcut(df['SMILES_Length'], q=10, labels=False)\n",
        "\n",
        "\n",
        "# Define loss function\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "\n",
        "# Evaluate the model on each bin\n",
        "for bin_id in range(10):\n",
        "    # Select data points in the current bin\n",
        "    bin_data = df[df['Bin'] == bin_id]\n",
        "\n",
        "    # Extract SMILES strings and labels\n",
        "    smiles_column_bin = bin_data['smiles']\n",
        "    labels_bin = bin_data['p_np'].values\n",
        "\n",
        "    # Tokenize and encode SMILES strings\n",
        "    encoded_smiles_list_bin = encode_smiles_strings(smiles_column_bin)\n",
        "\n",
        "    # Create data loader\n",
        "    dataset_bin = SMILESDataset(encoded_smiles_list_bin, labels_bin)\n",
        "    loader_bin = DataLoader(dataset_bin, batch_size=1, shuffle=False)\n",
        "\n",
        "    # Evaluate the model on the test set for the current bin\n",
        "    model.eval()\n",
        "    all_predictions_bin = []\n",
        "    all_labels_bin = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs_bin, labels_bin in loader_bin:\n",
        "            outputs_bin = model(inputs_bin)\n",
        "            predictions_bin = (outputs_bin > 0.5).float().numpy()\n",
        "            all_predictions_bin.extend(predictions_bin)\n",
        "            all_labels_bin.extend(labels_bin.numpy())\n",
        "\n",
        "    # Calculate test accuracy for the current bin\n",
        "    test_accuracy_bin = accuracy_score(all_labels_bin, all_predictions_bin)\n",
        "    print(f'Bin {bin_id + 1}/10, Test Accuracy: {test_accuracy_bin * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRNZMPaVdvrI",
        "outputId": "9fb5243f-0360-4deb-8b87-1949e3a6fafb"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bin 1/10, Test Accuracy: 88.58%\n",
            "Bin 2/10, Test Accuracy: 86.60%\n",
            "Bin 3/10, Test Accuracy: 87.74%\n",
            "Bin 4/10, Test Accuracy: 92.98%\n",
            "Bin 5/10, Test Accuracy: 92.27%\n",
            "Bin 6/10, Test Accuracy: 89.95%\n",
            "Bin 7/10, Test Accuracy: 91.87%\n",
            "Bin 8/10, Test Accuracy: 93.98%\n",
            "Bin 9/10, Test Accuracy: 94.15%\n",
            "Bin 10/10, Test Accuracy: 90.69%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BiLLSTM"
      ],
      "metadata": {
        "id": "h0pGZuvV7t7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define a list of SMILES symbols\n",
        "smiles_symbols = ['C', 'N', 'O', 'P', 'S', 'F', 'Cl', 'Br', 'I', 'H', 'B', 'Si', ' ', '(', ')', '=', '#', '1', '2', '3', '4', '5', '6', '7', '8', '9', '0', '+', '-', '[', ']', '@', '%', '.', '/']\n",
        "\n",
        "# Function to tokenize a SMILES string and create one-hot encodings\n",
        "def tokenize_smiles(smiles):\n",
        "    tokens = []\n",
        "    i = 0\n",
        "    while i < len(smiles):\n",
        "        char = smiles[i]\n",
        "        if char in smiles_symbols:\n",
        "            # Check if the next character forms a two-character element\n",
        "            potential_element = char + smiles[i + 1] if i + 1 < len(smiles) else None\n",
        "            if potential_element in smiles_symbols:\n",
        "                tokens.append(smiles_symbols.index(potential_element))\n",
        "                i += 2  # Skip the next character for a two-character element\n",
        "            else:\n",
        "                tokens.append(smiles_symbols.index(char))\n",
        "                i += 1\n",
        "        else:\n",
        "            # Handle other characters (non-SMILES symbols)\n",
        "            tokens.append(len(smiles_symbols))  # Assign a special index for non-SMILES symbols\n",
        "            i += 1\n",
        "    return tokens\n",
        "\n",
        "# Function to convert a list of SMILES strings to a list of one-hot encoded vectors\n",
        "def encode_smiles_strings(smiles_strings):\n",
        "    encoded_list = []\n",
        "    for smiles_string in smiles_strings:\n",
        "        tokenized_smiles = tokenize_smiles(smiles_string)\n",
        "        one_hot_encoding = np.zeros((len(tokenized_smiles), len(smiles_symbols) + 1))  # +1 for the special index\n",
        "        for i, token in enumerate(tokenized_smiles):\n",
        "            one_hot_encoding[i, token] = 1\n",
        "        encoded_list.append(one_hot_encoding)\n",
        "    return encoded_list\n",
        "\n",
        "# PyTorch dataset class for SMILES data\n",
        "class SMILESDataset(Dataset):\n",
        "    def __init__(self, smiles_list, labels):\n",
        "        self.smiles_list = smiles_list\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.smiles_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.smiles_list[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.float32)\n",
        "\n",
        "# Bidirectional LSTM model for classification\n",
        "class BiLSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(BiLSTMModel, self).__init__()\n",
        "        self.bilstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers, batch_first=True, bidirectional=True)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc = nn.Linear(hidden_size * 2, output_size)  # Multiply hidden_size by 2 for bidirectional\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        bilstm_out, _ = self.bilstm(x)\n",
        "        flattened = self.flatten(bilstm_out[:, -1, :])  # Take the output of the last time step\n",
        "        output = self.sigmoid(self.fc(flattened))\n",
        "        return output\n",
        "\n",
        "# Read CSV file and extract SMILES strings and labels\n",
        "csv_file_path = 'BBBP.csv'  # Replace with the actual path to your CSV file\n",
        "df = pd.read_csv(csv_file_path)\n",
        "smiles_column = df.iloc[:, 3]\n",
        "labels = df.iloc[:, 2].values  # Assuming labels are in the third column\n",
        "\n",
        "# Tokenize and encode SMILES strings\n",
        "encoded_smiles_list = encode_smiles_strings(smiles_column)\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(encoded_smiles_list, labels, test_size = 0.2, random_state = 0)\n",
        "train_dataset = SMILESDataset(X_train, y_train)\n",
        "test_dataset = SMILESDataset(X_test, y_test)\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "# Instantiate the BiLSTM model\n",
        "input_size = len(smiles_symbols) + 1  # +1 for the special index\n",
        "hidden_size = 64\n",
        "num_layers = 2\n",
        "output_size = 1\n",
        "model = BiLSTMModel(input_size, hidden_size, num_layers, output_size)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "\n",
        "    # Training loop\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels.view(-1, 1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Calculate training accuracy after each epoch\n",
        "    with torch.no_grad():\n",
        "          model.eval()\n",
        "          all_predictions = []\n",
        "          all_labels = []\n",
        "          for inputs, labels in train_loader:\n",
        "             outputs = model(inputs)\n",
        "             predictions = (outputs > 0.5).float().numpy()\n",
        "             all_predictions.extend(predictions)\n",
        "             all_labels.extend(labels.numpy())\n",
        "    train_accuracy = accuracy_score(all_labels, all_predictions)\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}, Train Accuracy: {train_accuracy * 100:.2f}%')\n",
        "# Evaluate the model on the test set\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    for inputs, labels in test_loader:\n",
        "        outputs = model(inputs)\n",
        "        predictions = (outputs > 0.5).float().numpy()\n",
        "        all_predictions.extend(predictions)\n",
        "        all_labels.extend(labels.numpy())\n",
        "\n",
        "# Calculate test accuracy\n",
        "test_accuracy = accuracy_score(all_labels, all_predictions)\n",
        "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdYnwhOD4zl0",
        "outputId": "7886da85-0cb5-43c4-f992-b7cc920708d5"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Train Accuracy: 81.22%\n",
            "Epoch 2/10, Train Accuracy: 78.17%\n",
            "Epoch 3/10, Train Accuracy: 82.38%\n",
            "Epoch 4/10, Train Accuracy: 79.82%\n",
            "Epoch 5/10, Train Accuracy: 79.27%\n",
            "Epoch 6/10, Train Accuracy: 83.23%\n",
            "Epoch 7/10, Train Accuracy: 83.96%\n",
            "Epoch 8/10, Train Accuracy: 84.21%\n",
            "Epoch 9/10, Train Accuracy: 84.15%\n",
            "Epoch 10/10, Train Accuracy: 85.67%\n",
            "Test Accuracy: 84.39%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ز"
      ],
      "metadata": {
        "id": "Pdo39RYnf_pF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ... (Rest of the code remains unchanged)\n",
        "\n",
        "# Function to calculate the length of SMILES strings\n",
        "def calculate_smiles_length(smiles):\n",
        "    return len(smiles)\n",
        "\n",
        "# Add a column for SMILES lengths to the DataFrame\n",
        "df['SMILES_Length'] = df['smiles'].apply(calculate_smiles_length)\n",
        "\n",
        "# Create 10 bins based on the SMILES lengths\n",
        "df['Bin'] = pd.qcut(df['SMILES_Length'], q=10, labels=False)\n",
        "\n",
        "\n",
        "# Define loss function\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "\n",
        "# Evaluate the model on each bin\n",
        "for bin_id in range(10):\n",
        "    # Select data points in the current bin\n",
        "    bin_data = df[df['Bin'] == bin_id]\n",
        "\n",
        "    # Extract SMILES strings and labels\n",
        "    smiles_column_bin = bin_data['smiles']\n",
        "    labels_bin = bin_data['p_np'].values\n",
        "\n",
        "    # Tokenize and encode SMILES strings\n",
        "    encoded_smiles_list_bin = encode_smiles_strings(smiles_column_bin)\n",
        "\n",
        "    # Create data loader\n",
        "    dataset_bin = SMILESDataset(encoded_smiles_list_bin, labels_bin)\n",
        "    loader_bin = DataLoader(dataset_bin, batch_size=1, shuffle=False)\n",
        "\n",
        "    # Evaluate the model on the test set for the current bin\n",
        "    model.eval()\n",
        "    all_predictions_bin = []\n",
        "    all_labels_bin = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs_bin, labels_bin in loader_bin:\n",
        "            outputs_bin = model(inputs_bin)\n",
        "            predictions_bin = (outputs_bin > 0.5).float().numpy()\n",
        "            all_predictions_bin.extend(predictions_bin)\n",
        "            all_labels_bin.extend(labels_bin.numpy())\n",
        "\n",
        "    # Calculate test accuracy for the current bin\n",
        "    test_accuracy_bin = accuracy_score(all_labels_bin, all_predictions_bin)\n",
        "    print(f'Bin {bin_id + 1}/10, Test Accuracy: {test_accuracy_bin * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XFjD5ZAebcu",
        "outputId": "c1d6be67-b961-452f-e534-30603a9ea62b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bin 1/10, Test Accuracy: 84.47%\n",
            "Bin 2/10, Test Accuracy: 85.05%\n",
            "Bin 3/10, Test Accuracy: 88.21%\n",
            "Bin 4/10, Test Accuracy: 93.86%\n",
            "Bin 5/10, Test Accuracy: 88.40%\n",
            "Bin 6/10, Test Accuracy: 85.93%\n",
            "Bin 7/10, Test Accuracy: 85.65%\n",
            "Bin 8/10, Test Accuracy: 82.87%\n",
            "Bin 9/10, Test Accuracy: 81.38%\n",
            "Bin 10/10, Test Accuracy: 77.45%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ه"
      ],
      "metadata": {
        "id": "2YpTuhFyL2ux"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FC"
      ],
      "metadata": {
        "id": "AzZoHABOQVUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Assuming 'encoded_df' is your dataframe containing the data\n",
        "\n",
        "X = encoded_df.iloc[:, :-1].values\n",
        "y = encoded_df.iloc[:, -1].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "X_tensor = X_tensor.view(-1, 39)\n",
        "\n",
        "# Define k-fold cross-validator\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize model, criterion, and optimizer\n",
        "model = SimpleNN(input_size=39)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Lists to store accuracy for each fold\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
        "    X_train_fold, X_test_fold = X_tensor[train_idx], X_tensor[test_idx]\n",
        "    y_train_fold, y_test_fold = y_tensor[train_idx], y_tensor[test_idx]\n",
        "\n",
        "    train_dataset_fold = TensorDataset(X_train_fold, y_train_fold)\n",
        "    train_loader_fold = DataLoader(train_dataset_fold, batch_size=32, shuffle=True)\n",
        "\n",
        "    num_epochs = 10\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "\n",
        "        for inputs, labels in train_loader_fold:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels.view(-1, 1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        y_train_pred_fold = (model(X_train_fold) > 0.5).float().numpy()\n",
        "    train_accuracy_fold = accuracy_score(y_train_fold, y_train_pred_fold)\n",
        "    train_accuracies.append(train_accuracy_fold)\n",
        "    print(f'Fold {fold + 1}/{kf.get_n_splits()}, Train Accuracy: {train_accuracy_fold * 100:.2f}%')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        y_pred_fold = (model(X_test_fold) > 0.5).float().numpy()\n",
        "\n",
        "    test_accuracy_fold = accuracy_score(y_test_fold, y_pred_fold)\n",
        "    test_accuracies.append(test_accuracy_fold)\n",
        "    print(f'Fold {fold + 1}/{kf.get_n_splits()}, Test Accuracy: {test_accuracy_fold * 100:.2f}%')\n",
        "\n",
        "# Calculate and print the average accuracy\n",
        "avg_train_accuracy = np.mean(train_accuracies)\n",
        "avg_test_accuracy = np.mean(test_accuracies)\n",
        "print(f'\\nAverage Train Accuracy: {avg_train_accuracy * 100:.2f}%')\n",
        "print(f'Average Test Accuracy: {avg_test_accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oXSf-DUL31x",
        "outputId": "0124c65e-5ccd-43ef-af61-e1b7f2d6c993"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1/5, Train Accuracy: 92.13%\n",
            "Fold 1/5, Test Accuracy: 87.07%\n",
            "Fold 2/5, Train Accuracy: 95.24%\n",
            "Fold 2/5, Test Accuracy: 92.44%\n",
            "Fold 3/5, Train Accuracy: 96.65%\n",
            "Fold 3/5, Test Accuracy: 91.46%\n",
            "Fold 4/5, Train Accuracy: 97.32%\n",
            "Fold 4/5, Test Accuracy: 93.90%\n",
            "Fold 5/5, Train Accuracy: 97.62%\n",
            "Fold 5/5, Test Accuracy: 95.12%\n",
            "\n",
            "Average Train Accuracy: 95.79%\n",
            "Average Test Accuracy: 92.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LSTM"
      ],
      "metadata": {
        "id": "QAaMxqrTQXKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define a list of SMILES symbols\n",
        "smiles_symbols = ['C', 'N', 'O', 'P', 'S', 'F', 'Cl', 'Br', 'I', 'H', 'B', 'Si', ' ', '(', ')', '=', '#', '1', '2', '3', '4', '5', '6', '7', '8', '9', '0', '+', '-', '[', ']', '@', '%', '.', '/']\n",
        "\n",
        "# Function to tokenize a SMILES string and create one-hot encodings\n",
        "def tokenize_smiles(smiles):\n",
        "    tokens = []\n",
        "    i = 0\n",
        "    while i < len(smiles):\n",
        "        char = smiles[i]\n",
        "        if char in smiles_symbols:\n",
        "            # Check if the next character forms a two-character element\n",
        "            potential_element = char + smiles[i + 1] if i + 1 < len(smiles) else None\n",
        "            if potential_element in smiles_symbols:\n",
        "                tokens.append(smiles_symbols.index(potential_element))\n",
        "                i += 2  # Skip the next character for a two-character element\n",
        "            else:\n",
        "                tokens.append(smiles_symbols.index(char))\n",
        "                i += 1\n",
        "        else:\n",
        "            # Handle other characters (non-SMILES symbols)\n",
        "            tokens.append(len(smiles_symbols))  # Assign a special index for non-SMILES symbols\n",
        "            i += 1\n",
        "    return tokens\n",
        "\n",
        "# Function to convert a list of SMILES strings to a list of one-hot encoded vectors\n",
        "def encode_smiles_strings(smiles_strings):\n",
        "    encoded_list = []\n",
        "    for smiles_string in smiles_strings:\n",
        "        tokenized_smiles = tokenize_smiles(smiles_string)\n",
        "        one_hot_encoding = np.zeros((len(tokenized_smiles), len(smiles_symbols) + 1))  # +1 for the special index\n",
        "        for i, token in enumerate(tokenized_smiles):\n",
        "            one_hot_encoding[i, token] = 1\n",
        "        encoded_list.append(one_hot_encoding)\n",
        "    return encoded_list\n",
        "\n",
        "# PyTorch dataset class for SMILES data\n",
        "class SMILESDataset(Dataset):\n",
        "    def __init__(self, smiles_list, labels):\n",
        "        self.smiles_list = smiles_list\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.smiles_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.smiles_list[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.float32)\n",
        "\n",
        "# LSTM model for classification\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        flattened = self.flatten(lstm_out[:, -1, :])  # Take the output of the last time step\n",
        "        output = self.sigmoid(self.fc(flattened))\n",
        "        return output\n",
        "\n",
        "# Read CSV file and extract SMILES strings and labels\n",
        "csv_file_path = 'BBBP.csv'  # Replace with the actual path to your CSV file\n",
        "df = pd.read_csv(csv_file_path)\n",
        "smiles_column = df.iloc[:, 3]\n",
        "labels = df.iloc[:, 2].values  # Assuming labels are in the third column\n",
        "\n",
        "# Tokenize and encode SMILES strings\n",
        "encoded_smiles_list = encode_smiles_strings(smiles_column)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(encoded_smiles_list, labels, test_size = 0.2, random_state = 0)\n",
        "train_dataset = SMILESDataset(X_train, y_train)\n",
        "test_dataset = SMILESDataset(X_test, y_test)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
        "\n",
        "# Lists to store accuracy for each fold\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "encoded_smiles_list = np.array(encoded_smiles_list)\n",
        "\n",
        "labels_array = np.array(labels)\n",
        "# Perform k-fold cross-validation\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(encoded_smiles_list, labels_array)):\n",
        "    X_train_fold, X_test_fold = encoded_smiles_list[train_idx], encoded_smiles_list[test_idx]\n",
        "    y_train_fold, y_test_fold = labels_array[train_idx], labels_array[test_idx]\n",
        "\n",
        "    train_dataset_fold = SMILESDataset(X_train_fold, y_train_fold)\n",
        "    test_dataset_fold = SMILESDataset(X_test_fold, y_test_fold)\n",
        "\n",
        "    train_loader_fold = DataLoader(train_dataset_fold, batch_size=1, shuffle=True)\n",
        "    test_loader_fold = DataLoader(test_dataset_fold, batch_size=1, shuffle=False)\n",
        "\n",
        "    input_size = len(smiles_symbols) + 1\n",
        "    hidden_size = 64\n",
        "    num_layers = 2\n",
        "    output_size = 1\n",
        "\n",
        "    model = LSTMModel(input_size, hidden_size, num_layers, output_size)\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Train the model\n",
        "    num_epochs = 10\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "\n",
        "        for inputs, labels in train_loader_fold:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels.view(-1, 1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Calculate training accuracy after each epoch\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        all_predictions_train = []\n",
        "        all_labels_train = []\n",
        "        for inputs, labels in train_loader_fold:\n",
        "            outputs = model(inputs)\n",
        "            predictions_train = (outputs > 0.5).float().numpy()\n",
        "            all_predictions_train.extend(predictions_train)\n",
        "            all_labels_train.extend(labels.numpy())\n",
        "    train_accuracy_fold = accuracy_score(all_labels_train, all_predictions_train)\n",
        "    train_accuracies.append(train_accuracy_fold)\n",
        "    print(f'Fold {fold + 1}/{kf.get_n_splits()}, Train Accuracy: {train_accuracy_fold * 100:.2f}%')\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        all_predictions_test = []\n",
        "        all_labels_test = []\n",
        "        for inputs, labels in test_loader_fold:\n",
        "            outputs = model(inputs)\n",
        "            predictions_test = (outputs > 0.5).float().numpy()\n",
        "            all_predictions_test.extend(predictions_test)\n",
        "            all_labels_test.extend(labels.numpy())\n",
        "\n",
        "    # Calculate test accuracy\n",
        "    test_accuracy_fold = accuracy_score(all_labels_test, all_predictions_test)\n",
        "    test_accuracies.append(test_accuracy_fold)\n",
        "    print(f'Fold {fold + 1}/{kf.get_n_splits()}, Test Accuracy: {test_accuracy_fold * 100:.2f}%')\n",
        "\n",
        "# Calculate and print the average accuracy\n",
        "avg_train_accuracy = np.mean(train_accuracies)\n",
        "avg_test_accuracy = np.mean(test_accuracies)\n",
        "print(f'\\nAverage Train Accuracy: {avg_train_accuracy * 100:.2f}%')\n",
        "print(f'Average Test Accuracy: {avg_test_accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQABrD5kN4l_",
        "outputId": "c98ac03b-7eff-41c8-b11a-d451bf5d764b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-211713bfacf1>:103: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  encoded_smiles_list = np.array(encoded_smiles_list)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1/5, Train Accuracy: 89.21%\n",
            "Fold 1/5, Test Accuracy: 85.12%\n",
            "Fold 2/5, Train Accuracy: 88.66%\n",
            "Fold 2/5, Test Accuracy: 84.39%\n",
            "Fold 3/5, Train Accuracy: 91.22%\n",
            "Fold 3/5, Test Accuracy: 86.34%\n",
            "Fold 4/5, Train Accuracy: 85.24%\n",
            "Fold 4/5, Test Accuracy: 80.00%\n",
            "Fold 5/5, Train Accuracy: 90.00%\n",
            "Fold 5/5, Test Accuracy: 87.32%\n",
            "\n",
            "Average Train Accuracy: 88.87%\n",
            "Average Test Accuracy: 84.63%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BiLSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(BiLSTMModel, self).__init__()\n",
        "        self.bilstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers, batch_first=True, bidirectional=True)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc = nn.Linear(hidden_size * 2, output_size)  # Multiply hidden_size by 2 for bidirectional\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        bilstm_out, _ = self.bilstm(x)\n",
        "        flattened = self.flatten(bilstm_out[:, -1, :])  # Take the output of the last time step\n",
        "        output = self.sigmoid(self.fc(flattened))\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "7lL8ckWpWb_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BILSTM"
      ],
      "metadata": {
        "id": "3AXP67bZWeml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels_array)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rX8AtkF5RXqu",
        "outputId": "1af59428-c1c6-4fe5-d453-656640802a71"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 ... 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define a list of SMILES symbols\n",
        "smiles_symbols = ['C', 'N', 'O', 'P', 'S', 'F', 'Cl', 'Br', 'I', 'H', 'B', 'Si', ' ', '(', ')', '=', '#', '1', '2', '3', '4', '5', '6', '7', '8', '9', '0', '+', '-', '[', ']', '@', '%', '.', '/']\n",
        "\n",
        "# Function to tokenize a SMILES string and create one-hot encodings\n",
        "def tokenize_smiles(smiles):\n",
        "    tokens = []\n",
        "    i = 0\n",
        "    while i < len(smiles):\n",
        "        char = smiles[i]\n",
        "        if char in smiles_symbols:\n",
        "            # Check if the next character forms a two-character element\n",
        "            potential_element = char + smiles[i + 1] if i + 1 < len(smiles) else None\n",
        "            if potential_element in smiles_symbols:\n",
        "                tokens.append(smiles_symbols.index(potential_element))\n",
        "                i += 2  # Skip the next character for a two-character element\n",
        "            else:\n",
        "                tokens.append(smiles_symbols.index(char))\n",
        "                i += 1\n",
        "        else:\n",
        "            # Handle other characters (non-SMILES symbols)\n",
        "            tokens.append(len(smiles_symbols))  # Assign a special index for non-SMILES symbols\n",
        "            i += 1\n",
        "    return tokens\n",
        "\n",
        "# Function to convert a list of SMILES strings to a list of one-hot encoded vectors\n",
        "def encode_smiles_strings(smiles_strings):\n",
        "    encoded_list = []\n",
        "    for smiles_string in smiles_strings:\n",
        "        tokenized_smiles = tokenize_smiles(smiles_string)\n",
        "        one_hot_encoding = np.zeros((len(tokenized_smiles), len(smiles_symbols) + 1))  # +1 for the special index\n",
        "        for i, token in enumerate(tokenized_smiles):\n",
        "            one_hot_encoding[i, token] = 1\n",
        "        encoded_list.append(one_hot_encoding)\n",
        "    return encoded_list\n",
        "\n",
        "# PyTorch dataset class for SMILES data\n",
        "class SMILESDataset(Dataset):\n",
        "    def __init__(self, smiles_list, labels):\n",
        "        self.smiles_list = smiles_list\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.smiles_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.smiles_list[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.float32)\n",
        "\n",
        "# LSTM model for classification\n",
        "class BiLSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(BiLSTMModel, self).__init__()\n",
        "        self.bilstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers, batch_first=True, bidirectional=True)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc = nn.Linear(hidden_size * 2, output_size)  # Multiply hidden_size by 2 for bidirectional\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        bilstm_out, _ = self.bilstm(x)\n",
        "        flattened = self.flatten(bilstm_out[:, -1, :])  # Take the output of the last time step\n",
        "        output = self.sigmoid(self.fc(flattened))\n",
        "        return output\n",
        "\n",
        "# Read CSV file and extract SMILES strings and labels\n",
        "csv_file_path = 'BBBP.csv'  # Replace with the actual path to your CSV file\n",
        "df = pd.read_csv(csv_file_path)\n",
        "smiles_column = df.iloc[:, 3]\n",
        "labels = df.iloc[:, 2].values  # Assuming labels are in the third column\n",
        "\n",
        "# Tokenize and encode SMILES strings\n",
        "encoded_smiles_list = encode_smiles_strings(smiles_column)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(encoded_smiles_list, labels, test_size = 0.2, random_state = 0)\n",
        "train_dataset = SMILESDataset(X_train, y_train)\n",
        "test_dataset = SMILESDataset(X_test, y_test)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
        "\n",
        "# Lists to store accuracy for each fold\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "encoded_smiles_list = np.array(encoded_smiles_list)\n",
        "\n",
        "labels_array = np.array(labels)\n",
        "# Perform k-fold cross-validation\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(encoded_smiles_list, labels_array)):\n",
        "    X_train_fold, X_test_fold = encoded_smiles_list[train_idx], encoded_smiles_list[test_idx]\n",
        "    y_train_fold, y_test_fold = labels_array[train_idx], labels_array[test_idx]\n",
        "\n",
        "    train_dataset_fold = SMILESDataset(X_train_fold, y_train_fold)\n",
        "    test_dataset_fold = SMILESDataset(X_test_fold, y_test_fold)\n",
        "\n",
        "    train_loader_fold = DataLoader(train_dataset_fold, batch_size=1, shuffle=True)\n",
        "    test_loader_fold = DataLoader(test_dataset_fold, batch_size=1, shuffle=False)\n",
        "\n",
        "    input_size = len(smiles_symbols) + 1\n",
        "    hidden_size = 64\n",
        "    num_layers = 2\n",
        "    output_size = 1\n",
        "\n",
        "    model = BiLSTMModel(input_size, hidden_size, num_layers, output_size)\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Train the model\n",
        "    num_epochs = 10\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "\n",
        "        for inputs, labels in train_loader_fold:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels.view(-1, 1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Calculate training accuracy after each epoch\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        all_predictions_train = []\n",
        "        all_labels_train = []\n",
        "        for inputs, labels in train_loader_fold:\n",
        "            outputs = model(inputs)\n",
        "            predictions_train = (outputs > 0.5).float().numpy()\n",
        "            all_predictions_train.extend(predictions_train)\n",
        "            all_labels_train.extend(labels.numpy())\n",
        "    train_accuracy_fold = accuracy_score(all_labels_train, all_predictions_train)\n",
        "    train_accuracies.append(train_accuracy_fold)\n",
        "    print(f'Fold {fold + 1}/{kf.get_n_splits()}, Train Accuracy: {train_accuracy_fold * 100:.2f}%')\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        all_predictions_test = []\n",
        "        all_labels_test = []\n",
        "        for inputs, labels in test_loader_fold:\n",
        "            outputs = model(inputs)\n",
        "            predictions_test = (outputs > 0.5).float().numpy()\n",
        "            all_predictions_test.extend(predictions_test)\n",
        "            all_labels_test.extend(labels.numpy())\n",
        "\n",
        "    # Calculate test accuracy\n",
        "    test_accuracy_fold = accuracy_score(all_labels_test, all_predictions_test)\n",
        "    test_accuracies.append(test_accuracy_fold)\n",
        "    print(f'Fold {fold + 1}/{kf.get_n_splits()}, Test Accuracy: {test_accuracy_fold * 100:.2f}%')\n",
        "\n",
        "# Calculate and print the average accuracy\n",
        "avg_train_accuracy = np.mean(train_accuracies)\n",
        "avg_test_accuracy = np.mean(test_accuracies)\n",
        "print(f'\\nAverage Train Accuracy: {avg_train_accuracy * 100:.2f}%')\n",
        "print(f'Average Test Accuracy: {avg_test_accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a03c951-819d-4f4d-f822-be25650c1d2e",
        "id": "57Sbn9-LWjjO"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-fdb04a1e6a5b>:103: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  encoded_smiles_list = np.array(encoded_smiles_list)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1/5, Train Accuracy: 84.15%\n",
            "Fold 1/5, Test Accuracy: 82.44%\n",
            "Fold 2/5, Train Accuracy: 90.18%\n",
            "Fold 2/5, Test Accuracy: 84.88%\n",
            "Fold 3/5, Train Accuracy: 90.24%\n",
            "Fold 3/5, Test Accuracy: 87.56%\n",
            "Fold 4/5, Train Accuracy: 88.96%\n",
            "Fold 4/5, Test Accuracy: 84.88%\n",
            "Fold 5/5, Train Accuracy: 89.57%\n",
            "Fold 5/5, Test Accuracy: 86.83%\n",
            "\n",
            "Average Train Accuracy: 88.62%\n",
            "Average Test Accuracy: 85.32%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#و\n",
        "\n",
        "فرق این دو مدل به نحوی است که باید اولا جنس داده به گونه ای باشد که اطلاع از اینده در تصمیم گیری الان ما نقش داشته باشد یا خیر\n",
        "\n",
        "قاعدتا دیتا ما جنسش خیلی اینگونه نمی باشد  و بیشتر متکی بر توالی می باشد تا اطلاع از اینده.\n",
        "\n",
        "اما به هرحال بایستی با لرن شدن بیشتر و دیتا های متنوع تر\n",
        "\n",
        "Bilstm\n",
        "\n",
        " حداقل به\n",
        " LSTM\n",
        "\n",
        " برسد اما به دلیل دیتا های ناکافی قدرت جنرالیزیشن زیادی ندارد\n",
        "\n",
        " به همین دلیل جنس دیتا که خیلی کامپتیبل با\n",
        "\n",
        " Bilstm\n",
        "\n",
        " نبود و دیتا های ناکافی منجر به همچین اختلافی میشد"
      ],
      "metadata": {
        "id": "dpSGVQ8KTxm-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ز\n",
        "\n",
        "\n",
        "\n",
        "این قسمت را در هر بخش انجام دادیم\n",
        "\n",
        "\n",
        "\n",
        "چیزی که مشاهده کردیم در\n",
        "\n",
        "FC\n",
        "\n",
        "با افزایش سایز دقت زیاد میشد\n",
        "\n",
        "در دو مدل دیگر هم چنین بود اما نوساناتی داشتیم\n",
        "\n",
        "\n",
        "که این به این مربوط است که ممکن است با افزایش  طول در دو مدل دیگر نابودی گرادیان به وجود بیاید و برای دیتای بیشتری این مذل ها خوب کار می کند ولی این داستان برای مذل\n",
        "\n",
        "FC\n",
        "\n",
        " فرقی ندارد و روند صعودی خودش را دارد"
      ],
      "metadata": {
        "id": "NFPriny4XUHc"
      }
    }
  ]
}