{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_UVrJQbwCZr"
      },
      "source": [
        "Analysing the deform convolution on COCO dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qn9Jv3ZHLO6S",
        "outputId": "095f0f16-0a3c-4358-c1ce-ed000943310c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fiftyone\n",
            "  Downloading fiftyone-0.23.1-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles (from fiftyone)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting argcomplete (from fiftyone)\n",
            "  Downloading argcomplete-3.2.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (4.11.2)\n",
            "Collecting boto3 (from fiftyone)\n",
            "  Downloading boto3-1.34.4-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m986.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from fiftyone) (5.3.2)\n",
            "Collecting dacite<1.8.0,>=1.6.0 (from fiftyone)\n",
            "  Downloading dacite-1.7.0-py3-none-any.whl (12 kB)\n",
            "Collecting Deprecated (from fiftyone)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting ftfy (from fiftyone)\n",
            "  Downloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: humanize in /usr/local/lib/python3.10/dist-packages (from fiftyone) (4.7.0)\n",
            "Collecting hypercorn>=0.13.2 (from fiftyone)\n",
            "  Downloading hypercorn-0.15.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Jinja2>=3 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (3.1.2)\n",
            "Collecting kaleido!=0.2.1.post1 (from fiftyone)\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from fiftyone) (3.7.1)\n",
            "Collecting mongoengine==0.24.2 (from fiftyone)\n",
            "  Downloading mongoengine-0.24.2-py3-none-any.whl (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.9/108.9 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting motor>=2.5 (from fiftyone)\n",
            "  Downloading motor-3.3.2-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fiftyone) (23.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.5.3)\n",
            "Requirement already satisfied: Pillow>=6.2 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (9.4.0)\n",
            "Requirement already satisfied: plotly>=4.14 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (5.15.0)\n",
            "Collecting pprintpp (from fiftyone)\n",
            "  Downloading pprintpp-0.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from fiftyone) (5.9.5)\n",
            "Collecting pymongo>=3.12 (from fiftyone)\n",
            "  Downloading pymongo-4.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (677 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m677.1/677.1 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from fiftyone) (2023.3.post1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from fiftyone) (6.0.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fiftyone) (2023.6.3)\n",
            "Collecting retrying (from fiftyone)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.2.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.19.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from fiftyone) (67.7.2)\n",
            "Collecting sseclient-py<2,>=1.7.2 (from fiftyone)\n",
            "  Downloading sseclient_py-1.8.0-py2.py3-none-any.whl (8.8 kB)\n",
            "Collecting sse-starlette<1,>=0.10.3 (from fiftyone)\n",
            "  Downloading sse_starlette-0.10.3-py3-none-any.whl (8.0 kB)\n",
            "Collecting starlette>=0.24.0 (from fiftyone)\n",
            "  Downloading starlette-0.34.0-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.3/70.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting strawberry-graphql==0.138.1 (from fiftyone)\n",
            "  Downloading strawberry_graphql-0.138.1-py3-none-any.whl (192 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.5/192.5 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.9.0)\n",
            "Collecting xmltodict (from fiftyone)\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Collecting universal-analytics-python3<2,>=1.0.1 (from fiftyone)\n",
            "  Downloading universal_analytics_python3-1.1.1-py3-none-any.whl (10 kB)\n",
            "Collecting fiftyone-brain<0.15,>=0.14 (from fiftyone)\n",
            "  Downloading fiftyone_brain-0.14.2-py3-none-any.whl (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.5/88.5 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fiftyone-db<2.0,>=0.4 (from fiftyone)\n",
            "  Downloading fiftyone_db-1.0.tar.gz (7.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting voxel51-eta<0.13,>=0.12 (from fiftyone)\n",
            "  Downloading voxel51_eta-0.12.1-py2.py3-none-any.whl (570 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m570.1/570.1 kB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from fiftyone) (4.8.1.78)\n",
            "Collecting graphql-core<3.3.0,>=3.2.0 (from strawberry-graphql==0.138.1->fiftyone)\n",
            "  Downloading graphql_core-3.2.3-py3-none-any.whl (202 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.9/202.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from strawberry-graphql==0.138.1->fiftyone) (2.8.2)\n",
            "Requirement already satisfied: typing_extensions<5.0.0,>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from strawberry-graphql==0.138.1->fiftyone) (4.5.0)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from fiftyone-brain<0.15,>=0.14->fiftyone) (1.11.4)\n",
            "Collecting h11 (from hypercorn>=0.13.2->fiftyone)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h2>=3.1.0 (from hypercorn>=0.13.2->fiftyone)\n",
            "  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting priority (from hypercorn>=0.13.2->fiftyone)\n",
            "  Downloading priority-2.0.0-py3-none-any.whl (8.9 kB)\n",
            "Collecting taskgroup (from hypercorn>=0.13.2->fiftyone)\n",
            "  Downloading taskgroup-0.0.0a4-py2.py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from hypercorn>=0.13.2->fiftyone) (2.0.1)\n",
            "Collecting wsproto>=0.14.0 (from hypercorn>=0.13.2->fiftyone)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3->fiftyone) (2.1.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.14->fiftyone) (8.2.3)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo>=3.12->fiftyone)\n",
            "  Downloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.4/300.4 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette>=0.24.0->fiftyone) (3.7.1)\n",
            "Collecting httpx>=0.10.0 (from universal-analytics-python3<2,>=1.0.1->fiftyone)\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill (from voxel51-eta<0.13,>=0.12->fiftyone)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.13,>=0.12->fiftyone) (0.18.3)\n",
            "Requirement already satisfied: glob2 in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.13,>=0.12->fiftyone) (0.7)\n",
            "Collecting jsonlines (from voxel51-eta<0.13,>=0.12->fiftyone)\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Collecting py7zr (from voxel51-eta<0.13,>=0.12->fiftyone)\n",
            "  Downloading py7zr-0.20.8-py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rarfile (from voxel51-eta<0.13,>=0.12->fiftyone)\n",
            "  Downloading rarfile-4.1-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.13,>=0.12->fiftyone) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.13,>=0.12->fiftyone) (1.16.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.13,>=0.12->fiftyone) (2.4.0)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.13,>=0.12->fiftyone) (5.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.13,>=0.12->fiftyone) (2.0.7)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->fiftyone) (2.5)\n",
            "Collecting botocore<1.35.0,>=1.34.4 (from boto3->fiftyone)\n",
            "  Downloading botocore-1.34.4-py3-none-any.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->fiftyone)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.10.0,>=0.9.0 (from boto3->fiftyone)\n",
            "  Downloading s3transfer-0.9.0-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.0/82.0 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated->fiftyone) (1.14.1)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->fiftyone) (0.2.12)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (3.1.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (3.2.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (2023.12.9)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (1.5.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fiftyone) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fiftyone) (3.2.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette>=0.24.0->fiftyone) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette>=0.24.0->fiftyone) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette>=0.24.0->fiftyone) (1.2.0)\n",
            "Collecting hyperframe<7,>=6.0 (from h2>=3.1.0->hypercorn>=0.13.2->fiftyone)\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Collecting hpack<5,>=4.0 (from h2>=3.1.0->hypercorn>=0.13.2->fiftyone)\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines->voxel51-eta<0.13,>=0.12->fiftyone) (23.1.0)\n",
            "Collecting texttable (from py7zr->voxel51-eta<0.13,>=0.12->fiftyone)\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting pycryptodomex>=3.16.0 (from py7zr->voxel51-eta<0.13,>=0.12->fiftyone)\n",
            "  Downloading pycryptodomex-3.19.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyzstd>=0.15.9 (from py7zr->voxel51-eta<0.13,>=0.12->fiftyone)\n",
            "  Downloading pyzstd-0.15.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (412 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.3/412.3 kB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyppmd<1.2.0,>=1.1.0 (from py7zr->voxel51-eta<0.13,>=0.12->fiftyone)\n",
            "  Downloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.9/138.9 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pybcj<1.1.0,>=1.0.0 (from py7zr->voxel51-eta<0.13,>=0.12->fiftyone)\n",
            "  Downloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multivolumefile>=0.2.3 (from py7zr->voxel51-eta<0.13,>=0.12->fiftyone)\n",
            "  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
            "Collecting inflate64<1.1.0,>=1.0.0 (from py7zr->voxel51-eta<0.13,>=0.12->fiftyone)\n",
            "  Downloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting brotli>=1.1.0 (from py7zr->voxel51-eta<0.13,>=0.12->fiftyone)\n",
            "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m99.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->voxel51-eta<0.13,>=0.12->fiftyone) (3.3.2)\n",
            "Building wheels for collected packages: fiftyone-db\n",
            "  Building wheel for fiftyone-db (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fiftyone-db: filename=fiftyone_db-1.0-py3-none-manylinux1_x86_64.whl size=42156134 sha256=50d95dedbbca00329459a2d993a2b57cfcce2534a95a5be2a26d9754e5bae2c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/e9/96/f5/c5ce4ab3c85b28eb34384db0f6af9cf6010b79606d7fe55a5a\n",
            "Successfully built fiftyone-db\n",
            "Installing collected packages: texttable, sseclient-py, pprintpp, kaleido, brotli, xmltodict, taskgroup, retrying, rarfile, pyzstd, pyppmd, pycryptodomex, pybcj, priority, multivolumefile, jsonlines, jmespath, inflate64, hyperframe, hpack, h11, graphql-core, ftfy, fiftyone-db, dnspython, dill, Deprecated, dacite, argcomplete, aiofiles, wsproto, strawberry-graphql, starlette, pymongo, py7zr, httpcore, h2, botocore, voxel51-eta, sse-starlette, s3transfer, motor, mongoengine, hypercorn, httpx, fiftyone-brain, universal-analytics-python3, boto3, fiftyone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Deprecated-1.2.14 aiofiles-23.2.1 argcomplete-3.2.1 boto3-1.34.4 botocore-1.34.4 brotli-1.1.0 dacite-1.7.0 dill-0.3.7 dnspython-2.4.2 fiftyone-0.23.1 fiftyone-brain-0.14.2 fiftyone-db-1.0 ftfy-6.1.3 graphql-core-3.2.3 h11-0.14.0 h2-4.1.0 hpack-4.0.0 httpcore-1.0.2 httpx-0.25.2 hypercorn-0.15.0 hyperframe-6.0.1 inflate64-1.0.0 jmespath-1.0.1 jsonlines-4.0.0 kaleido-0.2.1 mongoengine-0.24.2 motor-3.3.2 multivolumefile-0.2.3 pprintpp-0.4.0 priority-2.0.0 py7zr-0.20.8 pybcj-1.0.2 pycryptodomex-3.19.0 pymongo-4.6.1 pyppmd-1.1.0 pyzstd-0.15.9 rarfile-4.1 retrying-1.3.4 s3transfer-0.9.0 sse-starlette-0.10.3 sseclient-py-1.8.0 starlette-0.34.0 strawberry-graphql-0.138.1 taskgroup-0.0.0a4 texttable-1.7.0 universal-analytics-python3-1.1.1 voxel51-eta-0.12.1 wsproto-1.2.0 xmltodict-0.13.0\n"
          ]
        }
      ],
      "source": [
        "!pip install fiftyone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKaNNaoPLTBr",
        "outputId": "62a1f8fa-b4f8-4a2c-92c0-eecd6668e746"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Migrating database to v0.23.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:fiftyone.migrations.runner:Migrating database to v0.23.1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50\n",
        "from torchvision import transforms\n",
        "from pycocotools.coco import COCO\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import fiftyone.zoo as foz\n",
        "from torchvision.io.image import read_image\n",
        "from torchvision.models.segmentation import fcn_resnet50, FCN_ResNet50_Weights, lraspp_mobilenet_v3_large, LRASPP_MobileNet_V3_Large_Weights\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "from torchvision.models import resnet50, ResNet50_Weights, alexnet, AlexNet_Weights\n",
        "from torchvision.ops import deform_conv2d\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "import PIL.Image\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.io import read_image\n",
        "from torchvision.transforms.functional import to_pil_image, to_grayscale, to_tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZK2cOvVLcZn"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "classes = ['bicycle', 'car', 'cat', 'chair', 'cow', 'dog', 'horse', 'person', 'sheep']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWZC0XNQUrhH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Define the CNN model\n",
        "class SimpleCNNN(nn.Module):\n",
        "    def __init__(self, classes):\n",
        "        super(SimpleCNNN, self).__init__()\n",
        "        self.conv1=nn.Conv2d(in_channels=3, out_channels=2, kernel_size=3, stride=1, padding=1).to(device)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=16, stride=16)\n",
        "        self.fc1 = nn.Linear(2 * 14 * 14, len(classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.relu1(self.conv1(x)))\n",
        "        x = x.view(-1, 2 * 14 * 14)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "class COCO(Dataset):\n",
        "    def __init__(self, datasets, classes, transforms=None):\n",
        "        self.dataset = datasets\n",
        "        self.classes = classes\n",
        "        self.transform = transforms\n",
        "\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.dataset[idx]\n",
        "        image = Image.open(sample.filepath).convert('RGB')\n",
        "\n",
        "\n",
        "        label = np.zeros(len(self.classes), dtype=np.float32)\n",
        "\n",
        "        for detection in sample.ground_truth.detections:\n",
        "            if detection.label in classes:\n",
        "                label[classes.index(detection.label)] = 1.0\n",
        "        image = self.transform(image)\n",
        "\n",
        "        label = torch.tensor(label, dtype=torch.float64)\n",
        "\n",
        "        return image, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GREnj_vNMiDe",
        "outputId": "67bbb1e4-cbed-4681-83c5-5199026234fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading split 'train' to '/root/fiftyone/coco-2017/train' if necessary\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:fiftyone.zoo.datasets:Downloading split 'train' to '/root/fiftyone/coco-2017/train' if necessary\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading annotations to '/root/fiftyone/coco-2017/tmp-download/annotations_trainval2017.zip'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:fiftyone.utils.coco:Downloading annotations to '/root/fiftyone/coco-2017/tmp-download/annotations_trainval2017.zip'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 100% |██████|    1.9Gb/1.9Gb [2.8s elapsed, 0s remaining, 732.5Mb/s]      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:eta.core.utils: 100% |██████|    1.9Gb/1.9Gb [2.8s elapsed, 0s remaining, 732.5Mb/s]      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting annotations to '/root/fiftyone/coco-2017/raw/instances_train2017.json'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:fiftyone.utils.coco:Extracting annotations to '/root/fiftyone/coco-2017/raw/instances_train2017.json'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading 20000 images\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:fiftyone.utils.coco:Downloading 20000 images\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 100% |██████████████| 20000/20000 [39.5m elapsed, 0s remaining, 9.4 images/s]      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:eta.core.utils: 100% |██████████████| 20000/20000 [39.5m elapsed, 0s remaining, 9.4 images/s]      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing annotations for 20000 downloaded samples to '/root/fiftyone/coco-2017/train/labels.json'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:fiftyone.utils.coco:Writing annotations for 20000 downloaded samples to '/root/fiftyone/coco-2017/train/labels.json'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset info written to '/root/fiftyone/coco-2017/info.json'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:fiftyone.zoo.datasets:Dataset info written to '/root/fiftyone/coco-2017/info.json'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading 'coco-2017' split 'train'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:fiftyone.zoo.datasets:Loading 'coco-2017' split 'train'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 100% |█████████████| 20000/20000 [5.8m elapsed, 0s remaining, 61.5 samples/s]       \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:eta.core.utils: 100% |█████████████| 20000/20000 [5.8m elapsed, 0s remaining, 61.5 samples/s]       \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset 'coco-2017-train-20000' created\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:fiftyone.zoo.datasets:Dataset 'coco-2017-train-20000' created\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading split 'validation' to '/root/fiftyone/coco-2017/validation' if necessary\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:fiftyone.zoo.datasets:Downloading split 'validation' to '/root/fiftyone/coco-2017/validation' if necessary\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found annotations at '/root/fiftyone/coco-2017/raw/instances_val2017.json'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:fiftyone.utils.coco:Found annotations at '/root/fiftyone/coco-2017/raw/instances_val2017.json'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading 2000 images\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:fiftyone.utils.coco:Downloading 2000 images\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 100% |████████████████| 2000/2000 [3.9m elapsed, 0s remaining, 8.4 images/s]      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:eta.core.utils: 100% |████████████████| 2000/2000 [3.9m elapsed, 0s remaining, 8.4 images/s]      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing annotations for 2000 downloaded samples to '/root/fiftyone/coco-2017/validation/labels.json'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:fiftyone.utils.coco:Writing annotations for 2000 downloaded samples to '/root/fiftyone/coco-2017/validation/labels.json'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset info written to '/root/fiftyone/coco-2017/info.json'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:fiftyone.zoo.datasets:Dataset info written to '/root/fiftyone/coco-2017/info.json'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading 'coco-2017' split 'validation'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:fiftyone.zoo.datasets:Loading 'coco-2017' split 'validation'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 100% |███████████████| 2000/2000 [36.0s elapsed, 0s remaining, 45.1 samples/s]      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:eta.core.utils: 100% |███████████████| 2000/2000 [36.0s elapsed, 0s remaining, 45.1 samples/s]      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset 'coco-2017-validation-2000' created\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:fiftyone.zoo.datasets:Dataset 'coco-2017-validation-2000' created\n"
          ]
        }
      ],
      "source": [
        "dataset_train = foz.load_zoo_dataset(\n",
        "    \"coco-2017\",\n",
        "    split=\"train\",\n",
        "    label_types=[\"segmentations\"],\n",
        "    classes=classes,\n",
        "    max_samples=20000,\n",
        ")\n",
        "dataset_train = list(dataset_train)\n",
        "\n",
        "\n",
        "dataset_test = foz.load_zoo_dataset(\n",
        "    \"coco-2017\",\n",
        "    split=\"validation\",\n",
        "    label_types=[\"segmentations\"],\n",
        "    classes=classes,\n",
        "    max_samples=2000,\n",
        ")\n",
        "dataset_test = list(dataset_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jt9ovg4lP8_G"
      },
      "outputs": [],
      "source": [
        "# Define the transformation\n",
        "transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "trainset = COCO(datasets=dataset_train, classes=classes, transforms=transforms)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
        "\n",
        "testset = COCO(datasets=dataset_test, classes=classes, transforms=transforms)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDkMnDxoVG3d",
        "outputId": "2217c17f-a320-4444-89a0-c474a5e8635b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2792 Total Acc: 0.9109\n",
            "Per Class Acc: [0.9449641704559326, 0.8444964289665222, 0.9489451050758362, 0.8284733295440674, 0.9745720624923706, 0.9429737329483032, 0.9618332386016846, 0.7875199317932129, 0.9645203351974487]\n",
            "Train Loss: 0.2552 Total Acc: 0.9174\n",
            "Per Class Acc: [0.9604896903038025, 0.8443471193313599, 0.9486464858055115, 0.841610312461853, 0.9748706221580505, 0.9462579488754272, 0.9632762670516968, 0.7948347926139832, 0.982235312461853]\n",
            "Train Loss: 0.2511 Total Acc: 0.9174\n",
            "Per Class Acc: [0.9607882499694824, 0.8435012102127075, 0.9487957954406738, 0.841908872127533, 0.9753184914588928, 0.9459593892097473, 0.9626791477203369, 0.7951831221580505, 0.982533872127533]\n",
            "Train Loss: 0.2491 Total Acc: 0.9175\n",
            "Per Class Acc: [0.9607882499694824, 0.844894528388977, 0.9486464858055115, 0.8411624431610107, 0.9754677414894104, 0.9459593892097473, 0.9631270170211792, 0.7948845624923706, 0.9823845624923706]\n",
            "Train Loss: 0.2480 Total Acc: 0.9175\n",
            "Per Class Acc: [0.9604896903038025, 0.8454916477203369, 0.9489451050758362, 0.841610312461853, 0.9750199317932129, 0.9455115795135498, 0.9632762670516968, 0.7944864630699158, 0.982235312461853]\n",
            "Train Loss: 0.2462 Total Acc: 0.9174\n",
            "Per Class Acc: [0.9606389403343201, 0.8448447585105896, 0.9489451050758362, 0.8407145738601685, 0.9753184914588928, 0.9459593892097473, 0.9632762670516968, 0.7944366931915283, 0.9823845624923706]\n",
            "Train Loss: 0.2445 Total Acc: 0.9177\n",
            "Per Class Acc: [0.9607882499694824, 0.8444964289665222, 0.9489451050758362, 0.8420581221580505, 0.9754677414894104, 0.9462579488754272, 0.9629777073860168, 0.7954816818237305, 0.982533872127533]\n",
            "Train Loss: 0.2435 Total Acc: 0.9177\n",
            "Per Class Acc: [0.9606389403343201, 0.8453423976898193, 0.9489451050758362, 0.8422572016716003, 0.9753184914588928, 0.9459593892097473, 0.9632762670516968, 0.7951333522796631, 0.982533872127533]\n",
            "Train Loss: 0.2428 Total Acc: 0.9175\n",
            "Per Class Acc: [0.9598925113677979, 0.8457902073860168, 0.9489451050758362, 0.8419585824012756, 0.9752687215805054, 0.9458101391792297, 0.9631270170211792, 0.7947352528572083, 0.982235312461853]\n",
            "Train Loss: 0.2417 Total Acc: 0.9175\n",
            "Per Class Acc: [0.9600418210029602, 0.844894528388977, 0.9485967755317688, 0.842306911945343, 0.9754677414894104, 0.9461086988449097, 0.9632762670516968, 0.7945362329483032, 0.982533872127533]\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = SimpleCNNN(classes).to(device)\n",
        "\n",
        "\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    overall_accuracy = 0\n",
        "    accuracy_per_label = torch.zeros(len(classes), device=device)\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        preds = torch.sigmoid(outputs) > 0.5\n",
        "        correct_predictions = (preds == labels).float()\n",
        "\n",
        "        accuracy_per_label += correct_predictions.sum(0)/(len(labels))\n",
        "\n",
        "        overall_accuracy += correct_predictions.sum()/(len(labels)*(len(classes)))\n",
        "\n",
        "    accuracy_per_label /= len(trainloader)\n",
        "    running_loss /= len(trainloader)\n",
        "    overall_accuracy /= len(trainloader)\n",
        "\n",
        "    print(f'Train Loss: {running_loss:.4f} Total Acc: {overall_accuracy:.4f}')\n",
        "    print('Per Class Acc:', accuracy_per_label.tolist())\n",
        "\n",
        "\n",
        "print(\"Finished Training\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaseLX9hVGxv",
        "outputId": "380dcf5e-c129-4717-881c-468eb90197d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Acc: 0.9131\n",
            "Per Class Acc: [0.9523810148239136, 0.843254029750824, 0.9439484477043152, 0.8293651342391968, 0.9737103581428528, 0.9474207162857056, 0.9608135223388672, 0.785714328289032, 0.9816468954086304]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    overall_accuracy = 0\n",
        "    accuracy_per_label = torch.zeros(len(classes), device=device)\n",
        "\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = model(images)\n",
        "        preds = torch.sigmoid(outputs) > 0.5\n",
        "        correct_predictions = (preds == labels).float()\n",
        "\n",
        "        accuracy_per_label += correct_predictions.sum(0)/(len(labels))\n",
        "\n",
        "        overall_accuracy += correct_predictions.sum()/(len(labels)*(len(classes)))\n",
        "\n",
        "    accuracy_per_label /= len(testloader)\n",
        "\n",
        "    overall_accuracy /= len(testloader)\n",
        "\n",
        "    print(f'Total Acc: {overall_accuracy:.4f}')\n",
        "    print('Per Class Acc:', accuracy_per_label.tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kQOCUASPUqHd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class DeformableConv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False):\n",
        "        super(DeformableConv2d, self).__init__()\n",
        "\n",
        "        self.padding = padding\n",
        "\n",
        "        self.offset_conv = nn.Conv2d(in_channels, 2 * kernel_size * kernel_size,\n",
        "                                     kernel_size=kernel_size, stride=stride, padding=self.padding, bias=True).to(device)\n",
        "\n",
        "\n",
        "        nn.init.kaiming_normal_(self.offset_conv.weight, nonlinearity='relu')\n",
        "        nn.init.constant_(self.offset_conv.bias, 0.)\n",
        "\n",
        "\n",
        "        self.modulator_conv = nn.Conv2d(in_channels, 1 * kernel_size * kernel_size,\n",
        "                                        kernel_size=kernel_size, stride=stride, padding=self.padding, bias=True).to(device)\n",
        "\n",
        "        nn.init.kaiming_normal_(self.modulator_conv.weight, nonlinearity='relu')\n",
        "        nn.init.constant_(self.modulator_conv.bias, 0.)\n",
        "\n",
        "\n",
        "        self.regular_conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                                      kernel_size=kernel_size, stride=stride, padding=self.padding, bias=bias).to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h, w = x.shape[2:]\n",
        "        max_offset = max(h, w)\n",
        "\n",
        "        offset = self.offset_conv(x).clamp(-max_offset, max_offset).to(device)\n",
        "        modulator = 2. * torch.sigmoid(self.modulator_conv(x)).to(device)\n",
        "\n",
        "        grid = self.generate_grid(offset, x.shape).to(device)\n",
        "\n",
        "        x = F.grid_sample(x, grid, mode='bilinear', padding_mode='border')\n",
        "\n",
        "        x = self.regular_conv(x).to(device)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def generate_grid(self, offset, shape):\n",
        "        \"\"\"\n",
        "        Generate a grid for deformable convolution\n",
        "        \"\"\"\n",
        "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        batch_size, channel, height, width = shape\n",
        "\n",
        "        h_range = torch.arange(0, height).view(1, height, 1).expand(batch_size, -1, width).to(device)\n",
        "        w_range = torch.arange(0, width).view(1, 1, width).expand(batch_size, height, -1).to(device)\n",
        "\n",
        "        offset = offset / max(height, width)\n",
        "        offset = offset.permute(0, 2, 3, 1).contiguous().to(device)\n",
        "\n",
        "        grid = torch.stack([w_range + offset[..., 0], h_range + offset[..., 1]], dim=-1).to(device)\n",
        "\n",
        "        grid = 2.0 * grid / max(height, width) - 1.0\n",
        "\n",
        "        return grid\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yoPKRszid4z"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, classes):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1=DeformableConv2d(in_channels=3, out_channels=2, kernel_size=3, stride=1, padding=1).to(device)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=16, stride=16)\n",
        "\n",
        "\n",
        "        self.fc1 = nn.Linear(2 * 14 * 14, len(classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.relu1(self.conv1(x)))\n",
        "        x = x.view(-1, 2 * 14 * 14)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oky8QkYi7bz",
        "outputId": "78e14e01-2f98-423c-f372-fe3bdbb7f5b3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4296: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2927 Total Acc: 0.9124\n",
            "Per Class Acc: [0.9543192982673645, 0.8390724658966064, 0.9470541477203369, 0.8367834687232971, 0.970193088054657, 0.9382961988449097, 0.9622810482978821, 0.7865247130393982, 0.9768610596656799]\n",
            "Train Loss: 0.2584 Total Acc: 0.9176\n",
            "Per Class Acc: [0.9601910710334778, 0.8461385369300842, 0.9486464858055115, 0.8418591022491455, 0.9753184914588928, 0.9458101391792297, 0.9629777073860168, 0.7949841022491455, 0.982533872127533]\n",
            "Train Loss: 0.2533 Total Acc: 0.9176\n",
            "Per Class Acc: [0.9606389403343201, 0.8446457386016846, 0.9489451050758362, 0.8415107727050781, 0.9753184914588928, 0.9461086988449097, 0.9631270170211792, 0.7957802414894104, 0.9823845624923706]\n",
            "Train Loss: 0.2500 Total Acc: 0.9173\n",
            "Per Class Acc: [0.9606389403343201, 0.8438495397567749, 0.9484972357749939, 0.8406150341033936, 0.9753184914588928, 0.9458101391792297, 0.9632762670516968, 0.795033872127533, 0.9823845624923706]\n",
            "Train Loss: 0.2485 Total Acc: 0.9175\n",
            "Per Class Acc: [0.9606389403343201, 0.844894528388977, 0.9487957954406738, 0.8409136533737183, 0.9753184914588928, 0.9461086988449097, 0.9629777073860168, 0.7951333522796631, 0.9823845624923706]\n",
            "Train Loss: 0.2473 Total Acc: 0.9173\n",
            "Per Class Acc: [0.9604896903038025, 0.8433021903038025, 0.9489451050758362, 0.8407145738601685, 0.9754677414894104, 0.9459593892097473, 0.9632762670516968, 0.7947352528572083, 0.982533872127533]\n",
            "Train Loss: 0.2466 Total Acc: 0.9174\n",
            "Per Class Acc: [0.9600418210029602, 0.8444466590881348, 0.9487957954406738, 0.8410131335258484, 0.9753184914588928, 0.9459593892097473, 0.9628284573554993, 0.7953324317932129, 0.982533872127533]\n",
            "Train Loss: 0.2455 Total Acc: 0.9174\n",
            "Per Class Acc: [0.9604896903038025, 0.8444466590881348, 0.9483479261398315, 0.8412619829177856, 0.9754677414894104, 0.9458101391792297, 0.9632762670516968, 0.7946855425834656, 0.9823845624923706]\n",
            "Train Loss: 0.2452 Total Acc: 0.9173\n",
            "Per Class Acc: [0.9607882499694824, 0.8446954488754272, 0.9484474658966064, 0.840664803981781, 0.9754677414894104, 0.9458101391792297, 0.9628284573554993, 0.7943869829177856, 0.9823845624923706]\n",
            "Train Loss: 0.2446 Total Acc: 0.9173\n",
            "Per Class Acc: [0.9604896903038025, 0.8452428579330444, 0.9484474658966064, 0.8407643437385559, 0.9749701619148254, 0.9462579488754272, 0.9629777073860168, 0.7942874431610107, 0.9823845624923706]\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = SimpleCNN(classes).to(device)\n",
        "\n",
        "\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    overall_accuracy = 0\n",
        "    accuracy_per_label = torch.zeros(len(classes), device=device)\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        preds = torch.sigmoid(outputs) > 0.5\n",
        "        correct_predictions = (preds == labels).float()\n",
        "\n",
        "        accuracy_per_label += correct_predictions.sum(0)/(len(labels))\n",
        "\n",
        "        overall_accuracy += correct_predictions.sum()/(len(labels)*(len(classes)))\n",
        "\n",
        "    accuracy_per_label /= len(trainloader)\n",
        "    running_loss /= len(trainloader)\n",
        "    overall_accuracy /= len(trainloader)\n",
        "\n",
        "    print(f'Train Loss: {running_loss:.4f} Total Acc: {overall_accuracy:.4f}')\n",
        "    print('Per Class Acc:', accuracy_per_label.tolist())\n",
        "\n",
        "\n",
        "print(\"Finished Training\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VN9g0__gjQJJ",
        "outputId": "2708bd98-06c8-4f0a-acf4-fa6ba1e66f25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Acc: 0.9131\n",
            "Per Class Acc: [0.9523810148239136, 0.8437500596046448, 0.9434524178504944, 0.828869104385376, 0.9737103581428528, 0.9474207162857056, 0.9608135223388672, 0.7862103581428528, 0.9816468954086304]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    overall_accuracy = 0\n",
        "    accuracy_per_label = torch.zeros(len(classes), device=device)\n",
        "\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = model(images)\n",
        "        preds = torch.sigmoid(outputs) > 0.5\n",
        "        correct_predictions = (preds == labels).float()\n",
        "\n",
        "        accuracy_per_label += correct_predictions.sum(0)/(len(labels))\n",
        "\n",
        "        overall_accuracy += correct_predictions.sum()/(len(labels)*(len(classes)))\n",
        "\n",
        "    accuracy_per_label /= len(testloader)\n",
        "\n",
        "    overall_accuracy /= len(testloader)\n",
        "\n",
        "    print(f'Total Acc: {overall_accuracy:.4f}')\n",
        "    print('Per Class Acc:', accuracy_per_label.tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hvp3-yk9uZ0o",
        "outputId": "a35b9940-ba64-46cb-a14c-ee4313086802"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SimpleCNN(\n",
            "  (conv1): DeformableConv2d(\n",
            "    (offset_conv): Conv2d(3, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (modulator_conv): Conv2d(3, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (regular_conv): Conv2d(3, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  )\n",
            "  (relu1): ReLU()\n",
            "  (pool1): MaxPool2d(kernel_size=16, stride=16, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=392, out_features=9, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F26saNCzxcSN"
      },
      "source": [
        "Here we can see that in some classes the deform convolution has performed better than normal convolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2ECeSOrceMB"
      },
      "source": [
        "Analysing on Mnist dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WUT6PrbJfqsC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "def setup_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed) # if use multi-GPU\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    # torch.backends.cudnn.benchmark = True\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8xKwKCGoucLC"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "class MNISTClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 deformable=False):\n",
        "\n",
        "        super(MNISTClassifier, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv3 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        conv = nn.Conv2d if deformable==False else DeformableConv2d\n",
        "        self.conv4 = conv(32, 32, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.conv5 = conv(32, 32, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.gap = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(32, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = self.pool(x) # [14, 14]\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = self.pool(x) # [7, 7]\n",
        "        x = torch.relu(self.conv3(x))\n",
        "        x = torch.relu(self.conv4(x))\n",
        "        x = torch.relu(self.conv5(x))\n",
        "        x = self.gap(x)\n",
        "        x = x.flatten(start_dim=1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def train(model, loss_function, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = loss_function(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "def test(model, loss_function, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    num_data = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            org_data, target = data.to(device), target.to(device)\n",
        "\n",
        "            for scale in np.arange(0.5, 1.6, 0.1): # [0.5, 0.6, ... ,1.2, 1.3, 1.4, 1.5]\n",
        "                data = transforms.functional.affine(org_data, scale=scale, angle=0, translate=[0,0],shear=0)\n",
        "                output = model(data)\n",
        "                test_loss += loss_function(output, target).item()  # sum up batch mean loss\n",
        "                pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "                num_data += len(data)\n",
        "\n",
        "    test_loss /= num_data\n",
        "\n",
        "    test_acc = 100. * correct / num_data\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, num_data,\n",
        "        test_acc))\n",
        "    return test_acc\n",
        "\n",
        "\n",
        "def main(use_deformable_conv=False):\n",
        "    # Training settings\n",
        "    seed=1\n",
        "    setup_seed(seed)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    batch_size = 64\n",
        "    lr=1e-3\n",
        "    gamma=0.7\n",
        "    epochs=14\n",
        "\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    train_kwargs = {'batch_size': batch_size}\n",
        "    test_kwargs = {'batch_size': batch_size}\n",
        "    if use_cuda:\n",
        "        cuda_kwargs = {'num_workers': 2,\n",
        "                       'pin_memory': True,\n",
        "                       'shuffle': True}\n",
        "        train_kwargs.update(cuda_kwargs)\n",
        "        test_kwargs.update(cuda_kwargs)\n",
        "\n",
        "    train_transform = transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "        ])\n",
        "\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "        ])\n",
        "\n",
        "    dataset1 = datasets.MNIST('./data', train=True, download=True,\n",
        "                       transform=train_transform)\n",
        "    dataset2 = datasets.MNIST('./data', train=False,\n",
        "                       transform=transform)\n",
        "    train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
        "    test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
        "\n",
        "    model = MNISTClassifier(use_deformable_conv).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "    best_test_acc = 0.\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train(model, loss_function, device, train_loader, optimizer, epoch)\n",
        "        best_test_acc = max(best_test_acc, test(model, loss_function, device, test_loader))\n",
        "        scheduler.step()\n",
        "    print(\"best top1 acc(%): \", f\"{best_test_acc:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrTpbAZ9gCEe",
        "outputId": "782bbf8b-14eb-42b5-efc7-e71bbc533db0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0107, Accuracy: 88585/110000 (80.53%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0080, Accuracy: 92462/110000 (84.06%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0075, Accuracy: 93799/110000 (85.27%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0065, Accuracy: 95916/110000 (87.20%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0071, Accuracy: 95237/110000 (86.58%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0062, Accuracy: 96837/110000 (88.03%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0059, Accuracy: 97318/110000 (88.47%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0056, Accuracy: 97927/110000 (89.02%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0059, Accuracy: 97830/110000 (88.94%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0060, Accuracy: 97353/110000 (88.50%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0059, Accuracy: 97886/110000 (88.99%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0059, Accuracy: 97700/110000 (88.82%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0060, Accuracy: 97577/110000 (88.71%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0060, Accuracy: 97624/110000 (88.75%)\n",
            "\n",
            "best top1 acc(%):  89.02\n"
          ]
        }
      ],
      "source": [
        "main(use_deformable_conv=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMhKWl8mgCic",
        "outputId": "1952c339-a83f-4fd7-d9bf-5c8336b8ac86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 428624417.45it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 28435608.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 251285931.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 21550371.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4296: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0091, Accuracy: 90412/110000 (82.19%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0072, Accuracy: 93704/110000 (85.19%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0058, Accuracy: 97373/110000 (88.52%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0059, Accuracy: 96785/110000 (87.99%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0052, Accuracy: 98408/110000 (89.46%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0048, Accuracy: 99407/110000 (90.37%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0050, Accuracy: 98791/110000 (89.81%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0048, Accuracy: 99381/110000 (90.35%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0046, Accuracy: 99730/110000 (90.66%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0047, Accuracy: 99427/110000 (90.39%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0047, Accuracy: 99474/110000 (90.43%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0048, Accuracy: 99273/110000 (90.25%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0046, Accuracy: 99608/110000 (90.55%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0046, Accuracy: 99707/110000 (90.64%)\n",
            "\n",
            "best top1 acc(%):  90.66\n"
          ]
        }
      ],
      "source": [
        "main(use_deformable_conv=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "na4AiHxagd-V"
      },
      "source": [
        "Here we can also see that deform convolution has slightly performed better"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNQet-cjhBBt"
      },
      "source": [
        "Analysing on CIFAR10 dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l279FciBrV8j"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Check if GPU (CUDA) is available, otherwise, use CPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define the CNN model\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 8 * 8, 512)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.relu1(self.conv1(x)))\n",
        "        x = self.pool2(self.relu2(self.conv2(x)))\n",
        "        x = x.view(-1, 128 * 8 * 8)\n",
        "        x = self.relu3(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T64bzPe1se7r",
        "outputId": "cfc58a4f-86cc-4c74-9118-a574ff2e953e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: ./data/cifar-10-python.tar.gz\n",
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Finished Training\n",
            "Accuracy on the test set: 74.32%\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize to range [-1, 1]\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "# Instantiate the model\n",
        "model = SimpleCNN().to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Training the model\n",
        "epochs = 40\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:  # Print every 2000 mini-batches\n",
        "            print(f\"[Epoch {epoch + 1}, Batch {i + 1}] Loss: {running_loss / 2000:.3f}\")\n",
        "            running_loss = 0.0\n",
        "\n",
        "print(\"Finished Training\")\n",
        "\n",
        "# Testing the model\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy on the test set: {100 * correct / total:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zf0_sGABHl-d",
        "outputId": "40533069-1915-4bf5-f295-9969b0fc6f1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on the test set: 100.00%\n"
          ]
        }
      ],
      "source": [
        "# Testing the model\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in trainloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy on the test set: {100 * correct / total:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6t02k5oiss_D"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Check if GPU (CUDA) is available, otherwise, use CPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define the CNN model\n",
        "class SimpleCNNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNNN, self).__init__()\n",
        "        #self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv1=DeformableConv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1).to(device)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        #self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2=DeformableConv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1).to(device)\n",
        "\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 8 * 8, 512)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.relu1(self.conv1(x)))\n",
        "        x = self.pool2(self.relu2(self.conv2(x)))\n",
        "        x = x.view(-1, 128 * 8 * 8)\n",
        "        x = self.relu3(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xyd9yELtGnh8",
        "outputId": "ff352d66-cab8-488f-e6a4-b4336983fa48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 47665745.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4296: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished Training\n",
            "Accuracy on the test set: 71.48%\n",
            "Accuracy on the test set: 100.00%\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize to range [-1, 1]\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "# Instantiate the model\n",
        "model = SimpleCNNN().to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Training the model\n",
        "epochs = 40\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:  # Print every 2000 mini-batches\n",
        "            print(f\"[Epoch {epoch + 1}, Batch {i + 1}] Loss: {running_loss / 2000:.3f}\")\n",
        "            running_loss = 0.0\n",
        "\n",
        "print(\"Finished Training\")\n",
        "\n",
        "# Testing the model\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy on the test set: {100 * correct / total:.2f}%\")\n",
        "# Testing the model\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in trainloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy on the test set: {100 * correct / total:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfT7Y-_xja5X"
      },
      "source": [
        "در اینجا البته دفورم کانولوشن بهتر عمل نمی کند و یک اختلاف جزیی به دلیل نویز دارند\n",
        "\n",
        "\n",
        "\n",
        "و در کل در هر کدام از دیتاست ها یا دفورم کانولوشن کمی بهتر عمل کرده یا اختلاف جزیی با کانولوشن معمولی دارد\n",
        "\n",
        "\n",
        "و زمان طول کشیدن یادگیری شبکه با دفورم کانولوشن تا حدی بیشتر از کانولوشن معمولی بود زیرا خود دفورم کانولوشن شامل چندین محاسبه و کانولوشن معمولی می باشد"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#Q1\n",
        "\n",
        "\n",
        "Let's explore key distinctions in grid sampling:\n",
        "\n",
        "Standard Convolution:\n",
        "Fixed Sampling Grid: During the sampling process, convolutional filters adhere to a fixed grid pattern.\n",
        "Limited Flexibility: Standard convolutions demonstrate lower adaptability to changes and deformations in the input data.\n",
        "Deformable Convolution:\n",
        "Flexible Sampling Grid: Convolutional filters dynamically alter their sampling grid based on the input content.\n",
        "Enhanced Adaptability: Deformable convolutions excel in capturing deformable structures and intricate patterns in the data.\n",
        "A Comparative Analysis:\n",
        "Handling Complex Patterns: Deformable convolutions stand out in capturing intricate patterns and structures that may not conform to a regular grid.\n",
        "Adaptability Boost: The adaptive grid in deformable convolutions enables superior handling of variations in object shapes and positions.\n",
        "Performance Enhancement: In tasks involving object deformations, deformable convolutions often result in superior performance compared to standard convolutions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#Q2\n",
        "\n",
        "\n",
        "\n",
        "Let's delve into how Deformable Convolutional Networks foster flexibility amid geometric transformations:\n",
        "\n",
        "Dynamic Offsets Learning:\n",
        "\n",
        "Within deformable convolutional layers, the network introduces learnable offsets rather than relying on a fixed sampling grid.\n",
        "These offsets, additional parameters learned during training, dictate how convolutional filters sample input values, facilitating adaptation to geometric transformations.\n",
        "Adaptation of Spatial Sampling Grid:\n",
        "\n",
        "Deformable convolutions empower each location in the feature map to possess its own sampling grid.\n",
        "The sampling grid adjusts based on learned offsets, enabling the network to prioritize relevant regions and adapt to spatial transformations.\n",
        "Precision in Feature Localization:\n",
        "\n",
        "Deformable convolutions empower the network to pinpoint features more accurately, especially in the presence of deformations and variations in object shapes.\n",
        "Learnable offsets aid the network in focusing on informative regions, enhancing the capture of geometrically transformed patterns.\n",
        "Refined Object Localization:\n",
        "\n",
        "Traditional convolutional layers might face challenges in accurately localizing objects amid geometric transformations.\n",
        "Deformable convolutions enhance object localization by enabling the network to dynamically adjust its receptive field.\n",
        "Augmented Robustness:\n",
        "\n",
        "By permitting convolutional filters to adapt to the specific content of input data, deformable convolutions bolster the network's robustness to geometric transformations.\n",
        "This adaptability proves particularly advantageous in tasks where objects may undergo diverse deformations or changes in appearance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#Q3\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Let's examine the hurdles faced by standard convolutional layers when confronted with images featuring objects undergoing substantial spatial changes, such as rotations or deformations. Here are some explanations for why conventional convolutional layers might struggle in handling such scenarios:\n",
        "\n",
        "Rigidity in Sampling:\n",
        "\n",
        "Standard convolutions employ a fixed grid for sampling input values.\n",
        "This fixed grid may prove inadequate for capturing spatial variations or deformations in the input, particularly when objects undergo significant transformations.\n",
        "Constricted Receptive Field:\n",
        "\n",
        "Convolutional layers possess a limited receptive field, focusing on a local region of the input at a time.\n",
        "In instances of spatial transformations, standard convolutional layers may lack a sufficiently expansive receptive field to encompass the entire transformed object.\n",
        "Absence of Adaptability:\n",
        "\n",
        "Simple convolutional layers lack the capacity to adapt to the specific content of input data.\n",
        "When confronted with geometric transformations, a fixed convolutional grid may struggle to align with deformed structures, resulting in suboptimal feature extraction.\n",
        "Spatial Information Erosion:\n",
        "\n",
        "Rotation or deformation can lead to a loss of spatial information if the convolutional layer's receptive field is insufficiently large.\n",
        "Standard convolutions may face challenges in preserving spatial relationships between pixels, compromising the network's ability to comprehend transformed objects.\n",
        "Limited Transformation Handling:\n",
        "\n",
        "Simple convolutional layers are tailored for translation invariance but may falter in managing more intricate spatial transformations.\n",
        "While translation invariance is advantageous, it may prove insufficient when confronted with rotated or deformed objects.\n",
        "Localization Challenges:\n",
        "\n",
        "Standard convolutions may encounter difficulty in precisely localizing objects undergoing spatial changes.\n",
        "The fixed nature of the convolutional grid may contribute to imprecise object localization amid substantial transformations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#Q4\n",
        "\n",
        "\n",
        "\n",
        "In Deformable Convolutional Networks (DCNs), the offsets represent learnable parameters computed during the training process via backpropagation."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
